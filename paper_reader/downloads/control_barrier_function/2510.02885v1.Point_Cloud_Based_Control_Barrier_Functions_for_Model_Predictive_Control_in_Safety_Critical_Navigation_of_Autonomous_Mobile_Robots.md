## Point Cloud-Based Control Barrier Functions for Model Predictive Control in Safety-Critical Navigation of Autonomous Mobile Robots

Faduo Liang 1 , Yunfeng Yang 2 , and Shi-Lu Dai 1 , ∗

Abstract -In this work, we propose a novel motion planning algorithm to facilitate safety-critical navigation for autonomous mobile robots. The proposed algorithm integrates a real-time dynamic obstacle tracking and mapping system that categorizes point clouds into dynamic and static components. For dynamic point clouds, the Kalman filter is employed to estimate and predict their motion states. Based on these predictions, we extrapolate the future states of dynamic point clouds, which are subsequently merged with static point clouds to construct the forward-time-domain (FTD) map. By combining control barrier functions (CBFs) with nonlinear model predictive control, the proposed algorithm enables the robot to effectively avoid both static and dynamic obstacles. The CBF constraints are formulated based on risk points identified through collision detection between the predicted future states and the FTD map. Experimental results from both simulated and real-world scenarios demonstrate the efficacy of the proposed algorithm in complex environments. In simulation experiments, the proposed algorithm is compared with two baseline approaches, showing superior performance in terms of safety and robustness in obstacle avoidance. The source code is released for the reference of the robotics community.

## I. INTRODUCTION

Research on safety-critical optimal planning and control for autonomous mobile robots has been actively pursued over the past decades. Significant progress has been made in collision avoidance methods for both static and dynamic environments, with related algorithms becoming increasingly mature. However, reliable and efficient collision avoidance in environments containing both static (e.g., tables, shelves) and dynamic (e.g., pedestrians) obstacles remains a significant challenge.

A primary challenge in mobile robot navigation lies in accurately characterizing obstacles. Existing works [1], [2], [3], [4] typically model obstacles as ellipsoids through clustering and generate optimal trajectories under obstacle avoidance constraints. However, such approaches can lead to a certain

*This work was supported in part by the National Natural Science Foundation of China uunder Grant 42227901 and Grant 62473162, in part by the Guangdong Basic and Applied Basic Research Foundation under Grant 2024B1515120013, and in part by the Guangdong Emergency Management Science and Technology Program under Grant 2025YJKY002. (Corresponding author: Shi-Lu Dai.)

1 Faduo Liang and Shi-Lu Dai are with the School of Automation Science and Engineering, South China University of Technology, Guangzhou 510641, China, and also with the Southern Marine Science and Engineering Guangdong Laboratory (Zhuhai), Zhuhai 519000, China aulfd@mail.scut.edu.cn; audaisl@scut.edu.cn

2 Yunfeng Yang is with the Guangdong Academy of Safety Production and Emergency Management Science and Technology, Guangzhou, 510060, China yunfengyang1990@163.com

Code: https://github.com/Faduo-Liang/PCCBF-MPC.

The demonstrated video of the experiment may be found in the attached documents.

Fig. 1. Experimental results of navigation in an indoor environment with onboard sensing. Top left: an overview of the experimental setup and trajectory results. Top right: onboard color image. Bottom left: depth image. Bottom right: the optimized trajectory (green curve) through the hollow area inside the blackboard.

<!-- image -->

degree of conservativeness [5]. Firstly, density-based clustering methods like DBSCAN [6] are sensitive to variations in local data density and require careful tuning of parameters (e.g., eps and minPts), limiting their adaptability to highdimensional spaces [4]. Secondly, representing obstacles as ellipsoids reduces the available state space for robots [7]. This approach overestimates obstacle volumes by including irrelevant regions, such as hollow spaces, particularly for irregularly shaped obstacles, which restricts robot movement. Such over-approximation significantly impacts the feasibility and optimality of motion planning in complex environments. Recent studies [5], [8], [9] have proposed several important methods to characterize obstacles using point cloud data, but these methods still struggle to handle complex and dynamic environments effectively.

Jointly solving motion planning and control under perception constraints also presents substantial difficulties. Nonlinear model predictive control (NMPC) addresses these challenges by integrating planning and control into a unified constraint optimization framework [2]. However, despite its theoretical appeal, most approaches primarily use NMPC as an optimal controller, underutilizing its predictive capabilities and limiting their effectiveness in real-world applications. Recently, control barrier functions (CBFs) have emerged as a widely adopted method for enforcing safety constraints in obstacle avoidance. In [8], surface geometry was employed to locally define and synthesize a quadratic CBF over point cloud data. A MPC-DCBF framework was presented in [2] to address dynamic obstacle avoidance. However, these existing

Fig. 2. The proposed collision avoidance framework. The perception pipeline processes sensory data into occupancy voxel map. This occupancy voxel map is subsequently utilized to compute a forward-time-domain (FTD) map, which identifies static and dynamic risk points based on the nonlinear model predictive control (NMPC) prediction results. The points with the highest risk of collision (static risk points in blue and dynamic risk points in purple) are identified through collision detection. These high-risk points dynamically define safety constraints within the NMPC framework via control barrier functions, enabling safe collision-free navigation.

<!-- image -->

CBF-based methods still face challenges in simultaneously handling both dynamic and static obstacles.

To address these challenges, we propose a novel framework that integrates NMPC with point cloud-based CBFs to simultaneously handle both static and dynamic obstacles under real-time perception constraints. The contributions of our work are summarized as follows:

- 1) We develop a point cloud-based CBF-NMPC algorithm that integrates planning and control, enabling robots to generate safe and collision-free trajectories in unknown and dynamic environments.
- 2) We propose a heuristic method for identifying high-risk collision points using the forward-time-domain (FTD) map and the predictive capabilities of NMPC. This method effectively characterizes potential collisions and formulates CBFs for enhanced safety.
- 3) We conduct experiments in both Gazebo simulations and real-world scenarios. The results demonstrate the effectiveness and robustness of our safety-critical obstacle avoidance algorithm in unstructured environments with static and dynamic obstacles.

## II. RELATED WORK

## A. Dynamic Perception

Obstacle detection and tracking methods can be categorized into two groups based on the input data representations.

Image-Based Algorithms: In [10], [11], [12], depth images are utilized to generate U-depth and V-depth maps, enabling the classification of obstacles and the estimation of their states. However, these methods often represent static obstacles as ellipsoids, which can be overly conservative for complex-shaped obstacles [11]. In contrast to prior depth image-based approaches, a learning-based detector [13] is introduced to improve detection accuracy.

Point Cloud-Based Algorithms: Detection algorithms based on iterative closest point [14] match current point cloud segments to previous ones to estimate motion. Although effective for rigid objects like cars, this approach performs poorly for deformable objects such as humans, making it unsuitable for systems that prioritize human detection and tracking. A dynamic environment perception method was proposed in [4], where dynamic obstacles were modeled as ellipsoids using RGB-D camera data. In [13], a point cloud clustering method was combined with a YOLO detector for human detection.

Both image-based and point cloud-based algorithms can suffer from misdetection due to noise and environmental complexity. To address this, recent research [15] has focused on ensemble methods to mitigate their individual shortcomings. Our approach builds upon and extends the dynamic obstacle detection methods [15]. Specifically, we replace the human detector with our proposed YOLO-Fusion detector to reduce 3D bounding box estimation errors.

## B. Control Barrier Function-Based Collision Avoidance

In recent years, control barrier functions (CBFs) [2], [3], [5], [8], [16], [17], [18], [19] have gained significant attention for ensuring set invariance by considering system dynamics and guaranteeing forward invariance of the safe set. A control methodology was presented in [17] to unify CBFs and control Lyapunov functions (CLF) through quadratic programs (QP). A novel CLF-CBF-QP obstacle avoidance system [3] was designed for bipedal robots navigating among multiple non-overlapping obstacles. However, these methods rely on current state information without prediction, resulting in a greedy and short-sighted control policy.

In contrast, CBF-NMPC incorporates future state information to improve performance. A safety-critical model predictive control (MPC) strategy was presented in [16] to employ discrete-time CBFs, which guarantees system safety and yields a less greedy control policy. A MPC-DCBF framework [2] was developed for dynamic obstacle avoidance. However, these methods formulate CBFs by encapsulating obstacles with ellipsoids and representing the robot as a sphere, potentially leading to over-conservatism.

The synthesis of CBFs is one of the main challenges in utilizing CBF-based methods for navigation [20]. An online learning-based CBF controller were designed in [19] for static environments by stereo depth data. [8] presents a computationally low-cost framework for synthesizing barrier functions over point cloud data for safe vision-based control. However, these methods may suffer from collision issues in complex environments. To address this, we propose a CBF synthesis method that generates CBFs using a series of historical, current, and future risk points in the FTD map, enabling far-sighted and robust collision avoidance.

## C. Model Predictive Control-Based Trajectory Planning

A integrated planning and control framework was presented in [21], which relies on generating safe flight corridors to represent free space in the environment and employs multiple hyperplanes of polyhedrons as linear inequality constraints in the MPC problem to ensure flight safety. The integrated planning and control framework avoids dynamic objects in a reactive manner without tracking or predicting object movement. However, such reactive obstacle avoidance is fundamentally limited by the maneuverability of the quadrotor. Planned obstacle avoidance, which involves detecting, tracking, and predicting the movement of dynamic objects, could overcome this limitation and enable the avoidance of higher-speed moving objects. In [22] a trajectory generation method introduced based on MPC prediction, and on-demand collision avoidance was incorporated within a distributed MPC framework. This approach detects and resolves only the first collision within the finite prediction horizon, reducing computation time and increasing the success rate for transition tasks. Compared to [2], [16], which include all obstacles in the environment as constraints and utilize MPC prediction for dynamic obstacle avoidance, our approach extends on-demand collision avoidance to reduce computational load and enable real-time navigation in more general environments.

## III. DYNAMIC ENVIRONMENT PERCEPTION, PLANNING AND CONTROL

The objective is to enable an autonomous robot equipped with an RGB-D camera to navigate safely from start to goal in unknown environments containing static and dynamic obstacles. The robot must perceive its surroundings in real time and make decisions to avoid collisions while reaching its goal, without prior knowledge of the environment, such as the shape or state of the obstacles.

The algorithm flow of the system is illustrated in Fig. 2. The sensed depth data from the RGB-D camera is converted into an occupancy voxel map, which is then classified into dynamic and static point clouds. Using a Kalman filter, the current motion state of dynamic point clouds is estimated and used to generate the corresponding trajectory in the forward time domain. The predicted trajectory is sent to build the FTD map to identify risk points combined with the predicted state results from NMPC. These risk points are integrated into the NMPC optimization via CBFs, allowing the controller to enforce safety constraints during navigation.

## A. Dynamic Obstacle Detection

The perception module processes the depth image to generate raw point cloud data, which is then converted into an occupancy voxel map by applying the voxel filter proposed in [13] to remove the noise from the point cloud. We define the point cloud from occupancy voxel map as P static = { ( x i , y i , z i ) } M s i =0 in the spatial frame.

Pedestrians are common dynamic obstacles in indoor environments for robots. We introduce our YOLO-Fusion detector, which is based on 2D YOLOFastestDet and can

Fig. 3. Illustration of the YOLO-Fusion detector. The RGB image is first processed to obtain the 2D YOLO detection results, from which the corresponding bounding box on the depth image is derived. Using this 2D bounding box information, the proposed filtering method calculates the 3D bounding box for accurate object localization.

<!-- image -->

run in real-time on an onboard CPU. The architecture of the YOLO-Fusion detector is illustrated in Fig. 3. Unlike traditional image-based YOLO detectors, the YOLO-Fusion detector combines image data and point cloud data to achieve precise and stable 3D detection results, including depth and thickness. The detector first identifies the 2D bounding box of each pedestrian in the RGB image and then extracts the corresponding point clouds from the occupancy voxel map. To remove unrelated point clouds, we utilize the DBSCAN algorithm as a point cloud filter. This algorithm clusters the corresponding point clouds and selects the largest cluster as the detection result of the YOLO-Fusion detector. Finally, the size and position of the 3D obstacle's bounding box can be easily obtained from the filtered point clouds. Unlike [13], our approach does not require clustering all point clouds in the environment, thereby reducing unnecessary computational overhead.

Since this learning-based detector may still lack generalization ability, we combine our YOLO-Fusion detector with the robust detection framework [15], which integrates Udepth and DBSCAN detectors to identify universal dynamic obstacles.

## B. Local Map Construction

In this module, we aim to construct an FTD map that contains predictive information for the next N time steps. As dynamic obstacles are identified, their corresponding point clouds are removed from the static occupancy voxel map P static = { ( x i , y i , z i ) } M s i =0 and added to the dynamic map P dyn, 0 = { ( x i 0 , y i 0 , z i 0 ) } M d i =0 . Using a constant velocity model, a Kalman filter (KF) is employed to estimate and predict the motion state of the dynamic point cloud P dyn,k , resulting in P dyn,k = { ( x ik , y ik , z ik ) } M d i =0 , k = 0 , 1 , ..., N -1 . The FTD map is described by

<!-- formula-not-decoded -->

which contains the point cloud at the current time step and the predicted point clouds for the next N time steps.

To enhance query efficiency for risk point identification (Section III-E) and enable efficient collision checking, the local map is organized into N + 1 KD-Trees: one for the static map P static and N for the dynamic map P dyn,t at each time step. The structure of the FTD map is shown in Fig. 4.

Fig. 4. FTD map structure.

<!-- image -->

## C. CBF Generation

CBFs have been proven effective for obstacle avoidance in unmanned ground vehicles, e.g., [2], [8], [16]. For safetycritical control, we define a set C as the superlevel set of a continuously differentiable function h : X ⊂ R n → R :

<!-- formula-not-decoded -->

̸

where C is referred to as a safe set . The function h is a CBF [17] if ∂h ∂x = 0 for all x ∈ ∂ C and there exists an extended class K ∞ function γ , h satisfies

<!-- formula-not-decoded -->

Condition (3) can be extended to the discrete-time domain as follows

<!-- formula-not-decoded -->

where ∆ h (x k , u k ) := h (x k +1 ) -h (x k ) . By enforcing constraint (4), we derive h (x k +1 ) ≥ (1 -γ ) h (x k ) , indicating that the lower bound of h (x) decreases exponentially at a rate of 1 -γ [16]. According to the main CBF theorem, the safe set C is forward invariant and asymptotically stable [23]. Therefore, the robot position within C is also invariant and asymptotically stable, implying that the control system remains safe.

To ensure the system maintains a safe distance from potential collisions with the environment, we define the safe set C based on the system's knowledge of the environment, represented by a point cloud P FTD = { ( x i , y i , z i ) } M FTD i =1 in the spatial frame. The safety condition is defined using the barrier function:

<!-- formula-not-decoded -->

where δ &gt; 0 is a buffer that defines the minimum safe distance to the environment. Since h ( x k ) considers the minimum distance from the system to the point cloud, h ( x k ) &gt; 0 implies that the system is not in collision with any point in the point cloud.

To employ the barrier functions to the NMPC framework, we rewrite it as:

<!-- formula-not-decoded -->

where x ∗ p represents the risk points in the FTD map relative to the system's position x k at horizon step k .

## D. MPC-Based Planning and Control

The objective of MPC is to guide the robot to the target location while keeping it away from risk points represented by CBFs (Section III-E) and satisfying necessary physical constraints. At every discrete-time index t , the robot computes a new input sequence over the horizon through the following three steps:

- 1) Collision Checking: Detect potential future collisions using the latest predicted states computed at time t -1 of the robot and the FTD map.
- 2) Optimization Problem Construction: Formulate the optimization problem, including state and actuation constraints, and add collision constraints only if necessary.
- 3) Control Execution: Apply the first element of the obtained optimal input sequence to the robot.

Predicting collisions is the core idea behind risk point identification in CBF generation (Section III-E). This process repeats until the robot reaches the desired objective.

The robot's prediction model is described by the following discrete-time equation x t +1 = f ( x t , u t ) , where x t ∈ X ⊂ R n represents the states of the system at time step t ∈ Z + , and u t ∈ U ⊂ R m is the control inputs. Here, f ( · ) is locally Lipschitz as the differential-drive system model:

<!-- formula-not-decoded -->

with x t = [ x t , y t , θ t ] , where θ t represents the robot direction. We sample N -step horizon for the MPC and set the target location x tar as the goal of robot. The MPC problem is formulated as:

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

The cost function (8a) consists of stage cost q ( x t + k | t , u t + k | t ) = ∥ x tar -x t + k | t ∥ 2 Q + ∥ u t + k | t ∥ 2 R + ∥ x t + k | t -1 -x t + k | t ∥ 2 W , which represents target tracking error, control effort, and prediction variation error, respectively, and terminal cost p ( x t + N | t ) = ∥ x tar -x t + N | t ∥ 2 Q N , which represents terminal target tracking error. Here, Q , R , W , and Q N are weight matrices, while X , U , and X f represent

Fig. 5. Static risk point identification methodology. Forward detection and inverse collision detection leverage the FTD map data and NMPC predictions to identify static risk points.

<!-- image -->

the sets of admissible states, inputs, and terminal states, respectively. Note that incorporating the prediction variation error enables the robot to mitigate planning disturbances.

The MPC problem (8) includes four constraints. The first constraint is the model dynamics (8b), subject to the initial states (8d) estimated by odometry. The second constraint (8c) ensures the system states and inputs remain within feasible domains. The third constraint (8e) enforces the terminal set constraint. The fourth constraint incorporates the CBF constraints (8f), ensuring the robot remains in a safe state, avoiding collisions with dynamic and static risk points.

When the optimization problem (8) is successfully solved at time t , the optimal solution u ∗ t : t + N -1 | t = { u ∗ t | t , . . . , u ∗ t + N -1 | t } is obtained. The first element u ∗ t | t is applied as the control action. If the MPC fails at time t , the time interval ∆ T between the last successful step and the failed time t is calculated. The control action u ∗ t +∆ T | t -∆ T from the previously successful solution u ∗ t : t + N -1 | t -∆ T is used instead. This strategy ensures adaptability to MPC failures and guarantees a reasonable control action even when the MPC cannot be solved.

## E. Risk Point Identification

Unlike the existing CBF method [8], which selects the closest point cloud to generate CBFs, we introduce a heuristic approach for identifying high-risk static and dynamic collision points. This method effectively characterizes potential collisions and formulates CBFs to enhance safety by defining points that could potentially drive the robot away from the safe set as risk points.

Static Risk Point Identification: Building on the predictive capabilities of NMPC as inspired by [22], we propose the forward-inverse collision detector, as shown in Fig. 5. This detector identifies the first forward and first inverse predicted collisions with the FTD map and selects the corresponding collision point clouds as static risk points. Thanks to the

Fig. 6. Dynamic risk point identification methodology. At solving time t , the predicted path of the robot x t -1: t -1+ N -1 | t -1 is determined to identify dynamic risk point x ∗ t + k | t with dynamic obstacle P dyn,k for k = 0 , 1 , . . . , N -1 .

<!-- image -->

KD-Tree structure, collision detection is easy to implement. Forward detection enables rapid response to front obstacles, while inverse detection prevents the robot from becoming entrapped by single obstacles, making it suitable for multiobstacle scenarios. We focus on resolving only the most relevant predicted collision, proven to be both effective and computationally efficient. Unlike [22], our proposed method enforces CBFs as hard collision constraints rather than soft ones. The first predicted collision at time step k c within the previously considered horizon is defined as

<!-- formula-not-decoded -->

where δ s &gt; 0 represents the minimum static safe distance from the environment. At solving time t , the robot has information about the prediction trajectory computed at t -1 , meaning the collision is predicted to occur at time t -1+ k c . Herein, k c denotes the time step at which the robot predicts a collision with the static local map. The selected static risk point is denoted as x ∗ sta . To handle complex environments, we add x ∗ sta to the historical point set x ∗ his , which follows an updating principle that removes invalid historical risk points. The final risk description of the static map, represented by the historical point set x ∗ his , can manage extremely dense environments with an acceptable increase in computational cost.

For each static risk point x ∗ s ∈ x ∗ his at each time step k , we employ the following static barrier function:

<!-- formula-not-decoded -->

Dynamic Risk Point Identification: As shown in Fig. 6, to fully characterize irregular dynamic obstacles, we select dynamic risk points at each prediction time step within the

Fig. 7. Real-world experimental results. The illustrated settings encompass four principal obstacles. For each obstacle, four snapshots are provided to illustrate the motion generated by the proposed local planner. The right figure delineates the trajectory of our method, with the map color-coded according to height.

<!-- image -->

horizon. If the barrier function

<!-- formula-not-decoded -->

does not hold, then we select the point x ∗ t + k | t ∈ P dyn,k as the dynamic risk point at each prediction time step k . For each dynamic risk point x ∗ t + k | t at time step k , we employ the following dynamic barrier function:

<!-- formula-not-decoded -->

where δ d is the minimum dynamic safe distance from the environment, with δ d ≥ δ s &gt; 0 .

The static and dynamic barrier functions h sta and h dyn ensure that the safety set remains forward-invariant, providing a boundary that dynamically responds to both static and dynamic obstacles.

## IV. EXPERIMENTS

In this section, we present the experimental studies conducted in both real-world scenarios and simulation environments to validate the effectiveness of our proposed algorithm. The experiments are carried out under the ROS Noetic operating system. For the dynamic perception module, we configure the local perception range to 5 × 5 meters with a resolution of 0 . 1 meter, set the dynamic velocity threshold V dyn = 0 . 1 m/s, the dynamic voting threshold V vote = 0 . 8 m/s, and the maximum skip ratio T ratio = 0 . 5 . In the local planning module, the horizon length is set to N = 30 , and the optimization problem is solved using the Casadi solver [24]. The local perception module operates at 33 Hz, while the local planning module runs at 10 Hz. Both real-world and simulation experiments utilized the ZED2i RGB-D camera as the perception sensor, providing a wider field of view (FOV) and odometry-based positioning data. All algorithms are executed on a computer equipped with a 2.90 GHz AMD Ryzen 7 4800H CPU and an NVIDIA GTX 1650 GPU.

## A. Real-World Scenarios

A real-world experiment is conducted in an unknown indoor environment showed in Fig. 7, containing both static and dynamic objects, with limited camera FOV. We select the TurtleBot4 platform for the real-world experiment, setting its speed limits to 0 . 3 m/s for linear velocity and 1 . 2 rad/s for angular velocity. The distance from the starting point to the target point is set to 8 . 5 meters, and the pedestrian's walking speed is approximately 1 . 2 m/s. Considering the dimensions of TurtleBot4 and the accuracy of the RGB-D camera, the safe distance δ is set to 0 . 271 meters. The parameter γ in the CBF is set to 0 . 9 .

During the experiment, when TurtleBot4 encounters various static and dynamic obstacles of different shapes and sizes, our algorithm generated a safe trajectory to reach the target point. For instance, in Fig. 7, when TurtleBot4 encounters a blackboard-a hollow static obstacle with height restrictions and internal feasible domains, our algorithm successfully identifies the static risk points from the blackboard legs and choose to navigate through the inside rather than bypassing the obstacle, demonstrating less conservative behavior. When encountering pedestrians as dynamic obstacles, our algorithm predicates their future states over the next N steps and successfully identified the dynamic risk points

Fig. 8. Simulation Results. An environment featuring both static and dynamic obstacles is constructed within the Gazebo simulation platform. The autonomous ground robot, Jackal, is employed as the simulated agent. The robot successfully navigates to the target point while avoiding static obstacles (e.g., tables) and dynamic obstacles (e.g., pedestrians). Figs. (a) and (b) illustrate the simulation scenario and the outcomes achieved using our method. Figs (c), (d), and (e) provide detailed insights into the experimental setup and methodological aspects of static and dynamic obstacle avoidance.

<!-- image -->

to safely bypass the obstacles. This approach enhances the flexibility and adaptability of trajectory generation.

## B. Simulation Scenarios

Fig. 8 shows the simulation results, showcasing the optimized trajectories in a dynamic environment and a series of snapshots of the Jackal robot. To evaluate the performance of our proposed algorithm, we conducted comparative studies with two baseline methods:

- DCBF-NMPC [2]: An MPC approach that incorporates Kalman filter for obstacle trajectory prediction with uncertainty and a tracking controller that considers safety constraints using a dynamic CBF.
- Depth-CBF-QP [8]: A QP-based tracking controller that considers safety constraints using a depth control barrier function.

In all comparison studies, we utilize the Jackal robot as our simulation platform, setting its speed limits to 1 . 2 m/s for linear velocity and 1 . 2 rad/s for angular velocity. The distance from the starting point to the target point is set to 15 meters, and the pedestrian's walking speed is approximately 1 . 0 m/s. We evaluate the performance of each method using five metrics: the minimum distance to obstacles along the path ( µ d ), mean relative path length ( ˆ µ l ), mean relative smoothness ( ˆ µ s ), time spent from the start point to the end point ( µ t ), and success rate ( µ ). The comparison results are summarized in Table I.

The Depth-CBF-QP approach fails and collides with obstacles due to its lack of historical and future context, making it challenging to navigate in extremely dense environments. The DCBF-NMPC approach performers poorly with hollow obstacles because it uses ellipses to represent obstacles, leading to unnecessary conservatism in obstacle avoidance. Additionally, the DCBF-NMPC approach fails to identify and cluster irregular obstacles, resulting in failed control barrier function construction and subsequent collisions with objects such as tables. In contrast, our algorithm has successfully avoided all types of static and dynamic obstacles in a smooth and robust manner.

## V. CONCLUSION

This paper has presented a safety-critical algorithm for avoiding static and dynamic obstacles using an RGB-D camera. Initially, we constructed an FTD map by integrating the

TABLE I COMPARISON RESULTS WITH TWO BASELINE METHODS 1

| Algorithms   | µ d [ m ] ↓   | ˆ µ l ↓   | ˆ µ s ↓   | µ t [s] ↓   | µ ↑   |
|--------------|---------------|-----------|-----------|-------------|-------|
| Ours         | 0 . 327       | 1 . 000   | 1 . 00    | 16 . 10     | 100 % |
| DCBF-NMPC    | 0.609         | 1.086     | 1.98      | 20.75       | 70%   |
| Depth-CBF-QP | 0 (collided)  | -         | -         | -           | 0%    |

1 ↓ means the lower that metric, the better the performance, and vice versa. Bold numbers represent the metric-wise best performance.

YOLO-Fusion detector with a Kalman filter. Subsequently, risk points were identified from the FTD map, encapsulating both current and predicted future risk information of the environment. Leveraging these risk points, CBFs were formulated and integrated with NMPC to generate a safe, collision-free trajectory. In experimental studies, the proposed algorithm was compared with two baseline methods: DCBF-MPC and Depth-CBF-QP. Experimental results demonstrated that the proposed algorithm offers superior safety and robustness in obstacle avoidance compared to the baseline methods.

## REFERENCES

- [1] B. Brito, B. Floor, L. Ferranti, and J. Alonso-Mora, 'Model predictive contouring control for collision avoidance in unstructured dynamic environments,' IEEE Robotics and Automation Letters , vol. 4, no. 4, pp. 4459-4466, 2019.
- [2] Z. Jian, Z. Yan, X. Lei, Z. Lu, B. Lan, X. Wang, and B. Liang, 'Dynamic control barrier function-based model predictive control to safety-critical obstacle-avoidance of mobile robot,' in 2023 IEEE International Conference on Robotics and Automation (ICRA) , 2023, pp. 3679-3685.
- [3] J. Liu, M. Li, J. W. Grizzle, and J.-K. Huang, 'CLF-CBF constraints for real-time avoidance of multiple obstacles in bipedal locomotion and navigation,' in 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2023, pp. 10 497-10 504.
- [4] Y. Wang, J. Ji, Q. Wang, C. Xu, and F. Gao, 'Autonomous flights in dynamic environments with onboard vision,' in 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2021, pp. 1966-1973.
- [5] B. Dai, R. Khorrambakht, P. Krishnamurthy, and F. Khorrami, 'Sailing through point clouds: Safe navigation using point cloud based control barrier functions,' IEEE Robotics and Automation Letters , vol. 9, no. 9, pp. 7731-7738, 2024.
- [6] M. Ester, H.-P. Kriegel, J. Sander, and X. Xu, 'A density-based algorithm for discovering clusters in large spatial databases with noise,' in Knowledge Discovery and Data Mining , 1996. [Online]. Available: https://api.semanticscholar.org/CorpusID:355163
- [7] Z. Xu, X. Zhan, B. Chen, Y. Xiu, C. Yang, and K. Shimada, 'A real-time dynamic obstacle tracking and mapping system for UAV navigation and collision avoidance with an rgb-d camera,' in 2023 IEEE International Conference on Robotics and Automation (ICRA) , 2023, pp. 10 645-10 651.
- [8] M. De Sa, P. Kotaru, and K. Sreenath, 'Point cloud-based control barrier function regression for safe and efficient vision-based control,' in 2024 IEEE International Conference on Robotics and Automation (ICRA) , 2024, pp. 366-372.
- [9] A. Saviolo, N. Picello, R. Verma, and G. Loianno, 'Reactive collision avoidance for safe agile navigation,' ArXiv , vol. abs/2409.11962, 2024. [Online]. Available: https://api.semanticscholar.org/CorpusID: 272708361
- [10] H. Oleynikova, D. Honegger, and M. Pollefeys, 'Reactive avoidance using embedded stereo vision for MAV flight,' in 2015 IEEE International Conference on Robotics and Automation (ICRA) , 2015, pp. 50-56.
- [11] J. Lin, H. Zhu, and J. Alonso-Mora, 'Robust vision-based obstacle avoidance for micro aerial vehicles in dynamic environments,' in 2020 IEEE International Conference on Robotics and Automation (ICRA) , 2020, pp. 2682-2688.
- [12] A. Saha, B. C. Dhara, S. Umer, K. Yurii, J. M. Alanazi, and A. A. AlZubi, 'Efficient obstacle detection and tracking using RGB-D sensor data in dynamic environments for robotic applications,' Sensors , vol. 22, no. 17, 2022. [Online]. Available: https://www.mdpi.com/1424-8220/22/17/6537
- [13] T. Eppenberger, G. Cesari, M. Dymczyk, R. Siegwart, and R. Dub´ e, 'Leveraging stereo-camera data for real-time dynamic obstacle detection and tracking,' in 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2020, pp. 10 528-10 535.
- [14] S. Li and D. Lee, 'RGB-D SLAM in dynamic environments using static point weighting,' IEEE Robotics and Automation Letters , vol. 2, no. 4, pp. 2263-2270, 2017.
- [15] Z. Xu, X. Zhan, Y. Xiu, C. Suzuki, and K. Shimada, 'Onboard dynamic-object detection and tracking for autonomous robot navigation with RGB-D camera,' IEEE Robotics and Automation Letters , vol. 9, no. 1, pp. 651-658, 2024.
- [16] J. Zeng, B. Zhang, and K. Sreenath, 'Safety-critical model predictive control with discrete-time control barrier function,' in 2021 American Control Conference (ACC) , 2021, pp. 3882-3889.
- [17] A. D. Ames, J. W. Grizzle, and P. Tabuada, 'Control barrier function based quadratic programs with application to adaptive cruise control,' in 53rd IEEE Conference on Decision and Control , 2014, pp. 62716278.
- [18] I. Jang and H. J. Kim, 'Safe control for navigation in cluttered space using multiple Lyapunov-based control barrier functions,' IEEE Robotics and Automation Letters , vol. 9, no. 3, pp. 2056-2063, 2024.
- [19] R. K. Cosner, I. D. J. Rodriguez, T. G. Molnar, W. Ubellacker, Y. Yue, A. D. Ames, and K. L. Bouman, 'Self-supervised online learning for safety-critical control using stereo vision,' in 2022 International Conference on Robotics and Automation (ICRA) , 2022, pp. 11 48711 493.
- [20] B. Dai, P. Krishnamurthy, and F. Khorrami, 'Learning a better control barrier function,' 2022 IEEE 61st Conference on Decision and Control (CDC) , pp. 945-950, 2022. [Online]. Available: https://api.semanticscholar.org/CorpusID:248693543
- [21] W. Liu, Y. Ren, and F. Zhang, 'Integrated planning and control for quadrotor navigation in presence of suddenly appearing objects and disturbances,' IEEE Robotics and Automation Letters , vol. 9, no. 1, pp. 899-906, 2024.
- [22] C. E. Luis and A. P. Schoellig, 'Trajectory generation for multiagent point-to-point transitions via distributed model predictive control,' IEEE Robotics and Automation Letters , vol. 4, no. 2, pp. 375-382, 2019.
- [23] A. D. Ames, S. Coogan, M. Egerstedt, G. Notomista, K. Sreenath, and P. Tabuada, 'Control barrier functions: Theory and applications,' in 2019 18th European Control Conference (ECC) , 2019, pp. 34203431.
- [24] J. A. E. Andersson, J. Gillis, G. Horn, J. B. Rawlings, and M. Diehl, 'CasADi-A software framework for nonlinear optimization and optimal control,' Mathematical Programming Computation , vol. 11, no. 1, pp. 1-36, 2019.
## A framework for realisable data-driven active flow control using model predictive control applied to a simplified truck wake

Alberto Solera-Rico a,b, ∗ , Carlos Sanmiguel Vila a,b , Stefano Discetti b a Sub-directorate general of aeronautical systems, Spanish National Institute for Aerospace Technology

(INTA), ctra. M-301, km. 10.5, San Martín de la Vega, 28330, Madrid, Spain b Universidad Carlos III de Madrid, ROR: https://ror.org/03ths8210, Departamento de Ingeniería Aeroespacial, Avenida de la Universidad, 30, Leganés, 28911, Madrid, Spain

## Abstract

We present an efficient and realisable active flow control framework with few non-intrusive sensors. The method builds upon data-driven, reduced-order predictive models based on Long-Short-Term Memory (LSTM) networks and efficient gradient-based Model Predictive Control (MPC). The model uses only surface-mounted pressure probes to infer the wake state, and is trained entirely offline on a dataset built with open-loop actuations, thus avoiding the complexities of online learning. Sparsification of the sensors needed for control from an initially large set is achieved using SHapley Additive exPlanations. A parsimonious set of sensors is then deployed in closed-loop control with MPC. The framework is tested in numerical simulations of a 2D truck model at Reynolds number 500, with pulsed-jet actuators placed in the rear of the truck to control the wake. The parsimonious LSTM-MPC achieved a drag reduction of 12.8%.

Keywords: Active Flow Control, Model predictive control, Deep learning, SHAP, Fluid dynamics

## 1. Introduction

Active Flow Control (AFC) has emerged as a promising approach to reducing aerodynamic drag in ground and air vehicles. Manipulating separation and recovering base pressure with actuators such as steady and synthetic jets, plasma devices, and movable surfaces can produce meaningful performance gains, as surveyed in foundational reviews [1, 2, 3]. For ground vehicles in particular, wind tunnel studies in squareback or Ahmed-type models demonstrate drag reduction by steady and pulsed blowing with realistic actuator layouts [4, 5, 6]. Closed-loop real-time control implementations require controllers that are both

∗ Corresponding author

Email addresses: alberto.solera@alumnos.uc3m.es (Alberto Solera-Rico), csanmigu@ing.uc3m.es (Carlos Sanmiguel Vila), sdiscett@ing.uc3m.es (Stefano Discetti)

robust and computationally efficient [7]. Data-driven methods have become a leading strategy for developing predictive models [8, 9], which can be leveraged in the optimisation and control process.

The effectiveness of such MPC strategies is intrinsically related to the predictive power and computational efficiency of the underlying model. Pioneering early efforts in fluid mechanics focused on using an exact plant for MPC, with the aim of discovering control strategies to relaminarise a channel flow with blowing/suction [12]. Recent studies have successfully implemented deep model predictive control using a deep neural network for the plant model [13], and extended it for the case of limited sensors [14]. Self-tuning MPC frameworks have also been proposed, with automatic hyperparameter optimisation during training [15].

Model Predictive Control (MPC) offers an interesting framework for AFC thanks to its capability to include constraints and to adapt to disturbances and model inaccuracies [10, 11]. MPC is based on a predictive model of the system to forecast its future evolution under control actions. The control is optimised over a receding horizon, while respecting hard or soft constraints on the actuation and the system state itself. The optimised control is applied only for a short time, and then the optimisation is repeated again with updated state information. MPC can use predictive models trained entirely offline from existing data of the system undergoing open-loop control. Furthermore, MPC provides significant flexibility by decoupling the predictive model from the control objective. Control objectives are defined in an explicit cost function, which can be dynamically modified at deployment time to prioritise different goals, such as balancing drag reduction against energy consumption or enforcing constraints on actuator limits, without having to retrain the underlying model. This contrasts with other methods, such as typical reinforcement learning formulations, where the control objective is implicitly embedded within the trained policy through the reward function, often requiring extensive retraining to adapt to new goals or constraints.

The methods above leverage the hypothesis that the dynamical system to be modelled evolves on a low-dimensional attractor. Methods based on discovering governing equations from data [16, 17] or building deep-network predictors based on latent dynamics models have proven powerful in fluid flows. A low-dimensional compressed representation of the state of the system is learned, allowing highly efficient prediction and control [18, 9, 19, 20, 21]. The addition of a physical properties decoder to condition the low-dimensional representation with physical variables has proven to be a fruitful approach in various related fields [22, 23].

This study presents an end-to-end framework for developing a practical and computa-

Despite these advances, the transition to real applications requires overcoming a number of barriers. A primary challenge lies in sensor selection and placement. Many prominent studies rely on intrusive probes placed directly in the wake [24, 25, 26], which provide a clean observation of the flow state but are often impractical for real-world applications. Furthermore, reliance on closed-loop online training remains a major barrier to straightforward deployment. Finally, the computational cost of the MPC optimisation loop itself can be a bottleneck for real-time implementation if the underlying model is not suitable for efficient gradient-based methods [27]. These practical hurdles motivate the development of frameworks designed from the outset for experimental feasibility and computational tractability.

tionally efficient AFC system that directly addresses these challenges. Our goal is to create a robust controller using a methodology that is based on realistic sensing and is suitable for real-time deployment. The key contributions are threefold: 1) We develop a predictive model that relies exclusively on nonintrusive, surface-mounted pressure sensors, inferring the wake state from its surface pressure footprint; 2) a feature attribution method [28] is used to analyse the model and select the most important sensors to train a more efficient encoder network; 3) we implement the entire predictive model in a deep learning framework that supports automatic differentiation. This allows MPC optimisation to be performed with highly efficient gradient-based methods, making real-time control computationally feasible [29].

The paper is organised as follows. Section 2 provides a description of the methodology, including the data generation for the chosen test case, system modelling, sensor selection and control implementation. The analysis of the model and sensor selection, along with results of the control application are provided in § 3. Finally, the conclusions are discussed in § 4.

Finally, we demonstrate the efficacy of this framework by deploying the controller in a 2D simulation environment of the wake of a truck, using a minimal set of just four sensors identified through an interpretable analysis to achieve drag reduction.

## 2. Methodology

The methodology is designed with the aim of demonstrating the MPC framework and the sensor optimisation in a simulation environment, in which performances can be unambiguously assessed. The rationale of the method, nonetheless, is targeted to the practical application, i.e., parsimonious use of sensors and computationally slender predictive modelling. First, we generate a comprehensive dataset using random open-loop actuation sequences that serve as the basis for training our predictive model. This offline approach avoids the complex online training with the real system. Second, we train a model in the latent coordinate space to predict the aerodynamic forces from a history of surface pressure readings. Finally, we reduce the number of required sensors and train a lightweight 'slim' encoder for its use in a closed-loop control system. This approach enables the use of model-based and data-driven control strategies that are suitable for real-world deployment.

## 2.1. Flow configuration and data generation

As a test bench for the framework, we use a high-fidelity Direct Numerical Simulation (DNS) of a simplified 2D truck model. DNS provides an accurate representation of flow dynamics, capturing all scale features of the wake with minimal numerical approximations.

Figure 1 illustrates the flow configuration based on the horizontal mid plane geometry of the truck model from Ref. [30]. The model consists of a rectangular bluff body with width W = 1 , length L = 7 . 647 W , and rounded leading edges with radius r = 0 . 118 W . The inflow velocity is uniform with a magnitude of U ∞ , and the Reynolds number, defined as Re = U ∞ W/ν , where ν represents the kinematic viscosity of the fluid, is set to 500 . The computational domain is rectangular, extending from ( -7 W, 23 W ) in the streamwise ( x )

direction and ( -7 . 5 W, 7 . 5 W ) in the transverse ( y ) direction, with the front of the bluff body placed at x = 0 . The simulation domain is discretised with a hybrid mesh, structured near the wall and unstructured in the remaining region, spanning approximately 168 , 000 cells. Time is non-dimensionalised using the convective time t c = W/U ∞ . The DNS simulation is performed in OpenFOAM, using the Gym-preCICE [31] wrapper for the [32] coupling library and the OpenFOAM adapter [33] to couple the simulation with the controller.

Figure 1: Schematic of the flow configuration. Sensor locations depicted in blue and zero-net-mass flow jets schematised in red.

<!-- image -->

The control is achieved by two opposite-flow jets located on the sides of the vehicle base, with zero-net mass flow. This configuration is similar to previous experimental studies [34, 6]. The jets have a width of w jet = 0 . 05 W and produce parabolic velocity profiles with a maximum mean velocity of 1 . 5 U ∞ . The resulting dataset consists of a time series of pressure sensor readings, control intensity, and force data, with a time step of ∆ t = t c / 5 = W/ 5 U ∞ . The global mesh and a sample of the flow around the jets are shown in Figure 2.

Figure 2: DNS mesh and detail of the flow near the rear of the truck, with the jets actuating at maximum suction/blowing intensity.

<!-- image -->

The aerodynamic forces in the body are expressed in terms of the dimensionless drag and lift coefficients, C d and C l , which are computed directly from the OpenFOAM simulations. These coefficients are defined as

<!-- formula-not-decoded -->

where F x and F y are the streamwise and transverse forces acting on the body, ρ is the fluid density and A is the reference area of the bluff body. For the present 2D configuration,

the reference area is taken as the width of the body W multiplied by a unit depth. These coefficients integrate the pressure and viscous stress distributions over the body surface.

The training data was generated using forcing with an open-loop control. The control signal was specifically designed to excite the expected sensitive frequency range around the natural shedding frequency f sh ≈ 0 . 2 . The signal is a synthesised waveform characterised by simultaneous frequency and amplitude modulation, constructed as follows:

1. Carrier wave: A base sinusoidal wave with a fundamental frequency of f base = 0 . 2 , corresponding to the natural shedding frequency ( f sh ) of the wake, serves as the carrier.
2. Frequency Modulation (FM): To explore a range of temporal scales, the carrier frequency is modulated by a randomly varying signal. This is achieved by generating white noise and applying a second-order low-pass Butterworth filter with a cut-off frequency of 0 . 05 ( f sh / 4 ). The resulting filtered noise, η ( t ) , is normalised to [ -1 , 1] and modulates the instantaneous frequency according to f ( t ) = f base + k fm · η ( t ) , with a modulation index of k fm = 0 . 25 . This produces a smooth, wandering frequency that explores a range up to a maximum of 0.45.
3. Amplitude Modulation (AM): To ensure that the model learns the response of the system to the varying actuation power, the amplitude of the FM signal is modulated by a slow sinusoidal envelope with a frequency of 0 . 005 ( f sh / 40 ) and an amplitude depth of 45%. This causes the overall magnitude of the actuation to vary smoothly between low- and high-power regimes.

The final synthesised signal, shown in Figure 3, is clipped to a normalised range of [ -1 , 1] and then scaled to match the physical action limits of the synthetic jet, corresponding to a maximum flow rate of ± 0 . 075 .

The final dataset spans 52 , 500 time steps. This data was then augmented with the symmetric state and actuation during training to enhance generalisation and symmetry of the model.

During data generation simulation, the precomputed forcing signal was sampled at a control frequency of f s = 5 ( ∆ t = 0 . 2 ). The jet flow is linearly interpolated between these control updates to avoid discontinuities. This sequence spans 50 , 000 time steps. A shorter 2 , 500 -step sequence of uncontrolled dynamics is also added to the training dataset to improve generalisation. The simulation records the resulting wall pressure data from the N s = 90 sensor probes and the integrated aerodynamic forces ( C d , C l ). The sensors are evenly spaced with 40 on each side of the vehicle and 10 on the back, as shown in Figure 1.

For validation and testing, a separate 10 , 000 time steps dataset was used, generated with a linear chirp signal actuation. This chirp signal sweeps frequencies f chirp from 0 . 1 to 0 . 4 . This frequency range is entirely contained within the frequency domain explored by the modulated training signal, which reached a maximum of 0 . 45 as seen in Figure 3. This ensures that the test evaluates the ability of the model to accurately interpolate within its learnt dynamic range, rather than requiring it to extrapolate to unseen frequencies. The chirp signal also produces a small region of wake stabilisation, providing a valuable test case for the predictive capabilities of the model, as seen in Figure 5.

<!-- image -->

c

Figure 3: Sample portion of the modulated control signal applied during training data generation. Top: normalized signal. Bottom: Wavelet spectrogram of the same signal to show the frequency content over time.

## 2.2. Latent dynamics model

The proposed method is based on mapping sensor observations to a low-dimensional, learnt latent space, thus avoiding direct prediction of the high-dimensional full state. Within this compressed space, a more compact predictive model for the state evolution is inferred. The architecture, shown schematically in Fig. 4, is composed of three end-to-end trained neural network modules: a temporal encoder, which performs dimensionality reduction; an action-aware dynamics model, which serves as the predictive engine in the latent space; and a force decoder, which translates the latent state into physical quantities of interest such as force coefficients. By training the models simultaneously, the resulting latent space is optimised to be informative for prediction and correlated with the aerodynamic forces, as shown in previous studies [9, 21].

## 2.2.1. Temporal encoder

The first component, the temporal encoder, is responsible for feature extraction and dimensionality reduction. Its purpose is to distil the rich spatio-temporal information contained in the high-dimensional history of sensor measurements into a compact and generalisable latent state vector.

The input to the encoder at time t is a sequence of the last L = 32 sensor observations, denoted as S t = { s t -L +1 , ..., s t } , where each s ∈ R N s and N s is the number of sensors. The output is a single latent state vector z t ∈ R N z , where the latent dimension is N z = 8 ≪ N s × L . The latent dimension was selected by increasing it until the accuracy of the predictions made by the complete model reached a plateau. Increasing the latent dimension

Figure 4: Schematic of the model architecture. A history of sensor observations S t is mapped by the temporal encoder to a latent state z t . The action-aware dynamics model propagates this state forward to ˆ z t +1 using the current control action a t . The force decoder maps the latent state z t to the predicted aerodynamic force coefficients ˆ C t .

<!-- image -->

further tends to induce overfitting, whereas reducing it constrains the ability of the model to capture the dynamics of the system.

<!-- formula-not-decoded -->

Given the sequential nature of the input, the encoder has been implemented using a Long-Short-Term Memory (LSTM) network [35]. The LSTM processes the entire input sequence, and the hidden state from the final time step is passed through a Multi-Layer Perceptron (MLP) to produce the latent vector. This process is represented by the function f enc :

where θ enc represents the trainable weights of the encoder network.

## 2.2.2. Latent dynamics model

The latent dynamics model is the predictive engine of the model. It functions as a discrete-time state transition model within the learnt latent space, forecasting the evolution of the system one step into the future based on its current state and the applied control action. It takes as input the current latent state z t and the current control action a t ∈ R N a . The output is the latent state predicted at the next time step, ˆ z t +1 .

<!-- formula-not-decoded -->

The model first concatenates the current state z t and the current action a t . The resulting vector passes through an MLP, which is trained to predict the change in the latent state ∆ z t . Weadopt a residual connection, a common practice that stabilises training for dynamics models [36], so that the final prediction is the sum of the current state and the predicted change:

where f dyn represents the latent dynamics network with trainable weights θ dyn .

## 2.2.3. Force decoder

The force decoder provides the link from the abstract latent space back to the physical quantities required for control and evaluation. Its function is to provide an instantaneous estimate of the aerodynamic force coefficients from a given latent state vector.

The decoder is implemented as an MLP with residual connections (ResNet-style architecture). This design facilitates the training of deeper networks as it reduces the problem of vanishing gradients during training. Although the decoder is composed only of a few layers, during training, the gradient must flow through the three models, which justifies the use of residual connections. The mapping is given by:

The decoder takes a latent state vector z t ∈ R N z as input and outputs the predicted aerodynamic force coefficients, ˆ C t = [ ˆ C d , ˆ C l ] t ∈ R 2 .

<!-- formula-not-decoded -->

where θ dec are the trainable weights of the decoder. This component is trained concurrently with the rest of the model, ensuring that the latent space becomes structured in a way that is not only predictable in time, but also informative about the instantaneous aerodynamic forces. This latent-space conditioning was previously explored in Ref. [22] where it was proven to enhance the expressivity of the latent-space manifold with a coherent geometric structure.

## 2.2.4. Training procedure

First, the datasets are concatenated and the variables are standardised to zero mean and unit variance, with scaling parameters computed from the entire training dataset. The test dataset is scaled using these same parameters.

The three modules of the neural network (the encoder, the dynamics model, and the force decoder) are trained simultaneously in an end-to-end manner. This joint optimisation strategy ensures that the learnt latent space is not only predictable over time but also contains the necessary information for an accurate, instantaneous force estimation. Training is guided by a composite loss function L , which combines objectives for latent state prediction, force prediction, and latent space regularisation:

<!-- formula-not-decoded -->

where the weighting hyperparameters are set to λ force = 0 . 25 , λ var = 0 . 02 , and λ cov = 0 . 02 .

The latent state prediction loss in (5), L pred , penalises the discrepancy between the predicted latent state and the ground truth. To enhance long-term predictive stability, the loss is computed on an unrolled multistep prediction horizon. Starting from an initial state z t , the dynamics model is applied recursively for k = 5 steps to generate a sequence of predictions { ˆ z t +1 , ..., ˆ z t + k } . The ground truth sequence { z t +1 , ..., z t + k } is obtained by passing the corresponding true sensor histories through the encoder. The loss is L 2 norm computed over all steps of the sequence:

<!-- formula-not-decoded -->

The force prediction loss in (5), L force , ensures that the latent space remains physically meaningful by enforcing an accurate mapping of any latent state to its corresponding aerodynamic forces. At each step of the recursive prediction, the force decoder estimates the aerodynamic coefficients from the predicted latent state. This model uses dropout with a probability value 0 . 25 between layers to mitigate overfitting. This loss term measures the difference between the predicted forces ˆ C t + i and the true forces from the dataset C t + i . We employ a Smooth L 1 loss, which is less sensitive to outliers than L 2 . It behaves like an L 2 loss for small errors and an L 1 loss for large errors, defined as:

<!-- formula-not-decoded -->

where x is the element-wise error. The total force loss is the average over the prediction horizon:

<!-- formula-not-decoded -->

Finally, to prevent informational collapse and encourage a well-structured latent space, we introduce a regularisation loss inspired by the Variance-Invariance-Covariance (VICReg)

methodology [37]. This loss is composed of two parts that act on a batch of latent state predictions Z ∈ R B × D , where B is the batch size and D is the latent dimension.

- The variance loss in (5), L var , encourages the standard deviation of each latent dimension on the batch to be close to the unit. This prevents the representations from collapsing into a subspace.

<!-- formula-not-decoded -->

where ϵ is a small positive constant for numerical stability.

- The covariance loss in (5), L cov , pushes the off-diagonal elements of the covariance matrix of the latent variables towards zero, decorrelating the latent dimensions.

̸

<!-- formula-not-decoded -->

All trainable parameters in the three modules ( θ enc , θ dyn , and θ dec ) are updated jointly using the Adam optimiser [38], which minimises the total loss function L given in (5) by backpropagating through the unrolled computation graph. The batch size is B = 512 , the learning rate is 0.001 and the training spans 300 epochs.

## 2.3. Interpretable sensor selection

A key challenge in developing practical flow control systems is identifying a minimal and realisable but effective set of sensors. Although the initial model is trained offline on a dense array of 90 sensors to capture as much information as possible, deploying such a system would be costly and inefficient. We therefore implement a two-phase methodology to systematically reduce the number of sensors by ranking their importance and then training a new, computationally lightweight 'slim' encoder that operates only on the most informative sensor subset. In this way, the full sensor stack needs only to be used in the initial openloop dataset recording, while time-critical closed-loop implementation would rely on a small subset of sensors that can be more easily implemented.

## 2.3.1. SHAP-based ranking

To classify the sensors according to their importance, we interpret the trained temporal encoder using SHAP (SHapley Additive exPlanations) [28], a framework from cooperative game theory [39] to explain the output of the machine learning model. The Shapley value of a feature quantifies its average marginal contribution to a prediction in all possible combinations of features, providing a theoretically sound measure of importance. Since calculating exact Shapley values is computationally prohibitive, we employ the GradientExplainer algorithm from the SHAP library, which implements expected gradients , an extension of integrated gradients (IG) for differentiable models [40]. This method provides an efficient approximation for deep learning models by integrating the output gradients of the model with respect

to the input features, using a distribution of background samples as a reference for a typical input. The process therefore requires two datasets: a set of background samples ( 100 in our case) to define the baseline distribution, and a set of explanation samples ( 500 in our case) for which the feature importances are calculated.

This a posteriori methodology offers various advantages over embedded selection techniques, such as those that promote input sparsity using L 1 regularisation or reinforcement learning in an input gate layer [26, 41]. In those methods, the final number of active sensors is an indirect outcome of a sparsity hyperparameter, often requiring multiple training runs to achieve a specific target number of sensors. In contrast, our approach decouples sensor selection entirely from model training. By analysing a single fully-trained encoder, we generate an explicit importance ranking for all sensors. This provides complete flexibility, as the desired number of sensors becomes a design choice that can be made after the analysis. This not only simplifies the hyperparameter tuning process by removing the sparsity penalty term, but also provides a more direct and efficient path to designing sensor-reduced models tailored to specific needs or limitations.

The explainer produces SHAP values that quantify the contribution of each of the 90 sensors in each of the 32 time steps in the history window to each of the dimensions in the output latent state vector z t . To obtain a single, robust importance score for each sensor, we aggregate these values. First, we take the absolute SHAP value to measure the magnitude of the contribution, regardless of its sign. These magnitudes are then summed across all latent dimensions and subsequently averaged over both the explanation samples and the history window. This yields a single importance score for each of the 90 sensors.

## 2.3.2. Knowledge distillation for 'slim' encoder

Once the top N most informative sensors are identified, a new, computationally efficient 'slim' encoder is trained. This is achieved through a process of knowledge distillation, where the original 90-sensor encoder acts as a 'teacher' network to train a smaller 'student' network. The 'slim' encoder shares the same architecture as the original temporal encoder, but its input dimension is reduced from 90 to the selected N sensors.

The objective is to distil the knowledge of the teacher model into the student, enabling the 'slim' encoder to reproduce the latent space structure of the original model using only a fraction of the sensor input. During this process, the weights of the teacher encoder are frozen. For each batch of training data, the full 90 -sensor history S t is passed through the teacher to generate a target latent vector z t, target . Simultaneously, the corresponding subset of the data from the N selected sensors, S t, slim , is fed into the 'slim' trainable encoder to produce a prediction, z t, slim . The student network is then optimised by minimising the L 2 norm between its output and the target vector of the teacher.

<!-- formula-not-decoded -->

where B is the number of samples in the batch.

This procedure creates a lightweight encoder that requires significantly fewer sensors. Crucially, it can be used interchangeably with the original one for downstream tasks without retraining the latent dynamics model or the force decoder. This decoupling greatly reduces the physical and computational requirements for the deployment of real-world control systems.

## 2.4. Latent-space model predictive control

With the trained and validated model, we can formulate a closed-loop control strategy to minimise aerodynamic drag. MPC is a natural framework for this task, as it leverages the predictive capabilities of the model to make optimal decisions over a finite time horizon. A key advantage of our approach is that the entire optimisation process occurs within the computationally efficient, differentiable, low-dimensional latent space, which makes it suitable for real-time applications.

At each control step t , the controller uses the history of the last L sensor observations S t and the encoder to establish the initial state. The objective is to find an optimal sequence of future control actions, U ∗ t = { a ∗ t , . . . , a ∗ t + H -1 } , over a prediction horizon of H = 25 steps, approximately one shedding cycle, that minimises a predefined cost function J MPC , which will be introduced later.

## 2.4.1. Cost function

The cost function is designed to achieve the primary goal of drag reduction while adhering to practical control constraints. The total cost, J MPC , is a weighted sum of terms penalising undesirable behaviour over the prediction horizon:

<!-- formula-not-decoded -->

where the drag, lift, and control components are defined below.

<!-- formula-not-decoded -->

The cost related to drag, J drag , combines two objectives: to minimise the mean drag relative to a baseline and to penalise large fluctuations in drag to encourage stability of the wake.

Here, C d, ref = 1 . 051 is the mean drag of the uncontrolled case and w amp = 0 . 1 is a weighting factor. The lift-suppression cost, J lift , penalises the mean absolute lift coefficient with the weighting factor w C l = 0 . 01 to discourage asymmetric wake states:

<!-- formula-not-decoded -->

Finally, the control cost, J control , regulates the actuation signal. Effective regularisation is critical for two reasons: first, from a practical standpoint, smooth control signals are

necessary to reduce actuator fatigue and energy consumption. Second, from a modelling perspective, rapidly changing control actions can degrade the predictive accuracy of the data-driven model by forcing it into out-of-distribution states not well represented in the training data.

Although the framework allows for penalising various aspects of the control signal, including total effort and rate of change, empirical tuning revealed that a single term promoting the smoothness of the control sequence was sufficient for effective regularisation. The final control cost is therefore defined as:

<!-- formula-not-decoded -->

This control smoothness term penalises the mean square difference between consecutive actions within the prediction horizon. In our implementation, it is weighted with w smooth = 8 . 0 , which was found to produce stable and effective control actions.

## 2.4.2. Optimization

The optimal control sequence, { a ∗ t + k } H -1 k =0 , is found using a gradient-based optimisation approach. A key advantage of our framework, and a solution to the high computational cost often associated with MPC, is the implementation of the entire predictive model (encoder, dynamics, and decoder) in Pytorch [42]. This makes the cost function J MPC fully differentiable with respect to the sequence of future actions. We can therefore leverage automatic differentiation to compute the exact gradient of the cost function via backpropagation through the unrolled model predictions. This is significantly more efficient than derivative-free methods or numerical approximations, making the optimisation tractable for real-time control.

The optimisation process at each control step is as follows:

1. Initialisation: The sequence of actions is initialised. To ensure temporal consistency and accelerate convergence, we employ a warm-start strategy where the initial guess is the optimised sequence from the previous time step, shifted forward by one step.
2. Prediction: Starting with the current latent state z t = f enc ( S t ) , the dynamics model is recursively applied for H steps, using actions from the current sequence, to generate a sequence of future latent states { ˆ z t +1 , . . . , ˆ z t + H } . The force decoder then maps this sequence to the predicted forces { ˆ C t +1 , . . . , ˆ C t + H } .
3. Optimisation: The Adam optimiser [38] is used to update the action sequence for a small number of iterations (typically 5), using a learning rate of 10 -3 , to minimise the cost J MPC . Control actions are constrained to their physical limits at each iteration.
4. Receding horizon: Following the receding horizon principle, only the first action of the final optimised sequence, a ∗ t , is applied to the flow simulation. The rest of the sequence is discarded (except for initialisation in the next step), and the whole process is repeated in the next time step t +1 , using new sensor measurements.

## 3. Results

## 3.1. Model performance and latent space structure

The performance of the trained model is evaluated on the test dataset, which was generated using a chirp actuation signal to assess the generalisation capabilities of the model across a range of frequencies. To evaluate the performance of the force decoder, Figure 5 presents a comparison between the mapped aerodynamic forces and the ground truth values of the dataset, using only the encoder and decoder networks, without prediction. The model demonstrates high fidelity in its estimates, achieving a coefficient of determination ( R 2 ) of 0.94 for C d and 0.96 for C l . This finding verifies that the model accurately predicts instantaneous forces from sensor history across various actuation frequencies, including wake stabilization areas, thus offering a reliable basis for the control system.

Figure 5: Comparison between the aerodynamic force coefficients estimated by the force decoder and the ground truth values from the test dataset using a chirp actuation signal with instantaneous frequency f chirp . The plot shows a range where the wake briefly stabilises and the highest frequency region. The dashed blue line represents the prediction and the solid black line represents the reference values.

<!-- image -->

A key aspect of our framework is the emergence of a low-dimensional latent space that is not only predictable, but also physically meaningful. To investigate its structure, Figure 7 presents a pair plot of the eight latent space variables from the training data. The diagonal elements display histograms for each latent variable, while the off-diagonal plots, coloured by the instantaneous lift (top triangle) and drag (bottom triangle) coefficients, illustrate the relationships between pairs. The visualisation reveals a highly-structured latent space. For example, the relationship between latent variables 1 and 2 forms a distinct V-shaped manifold. Each arm of the V corresponds to an opposite sign of the lateral force, while

<!-- image -->

d

l

Figure 6: Comparison between the aerodynamic force coefficients estimated by the force decoder and the ground truth values from the test dataset using a chirp actuation signal. The colour scale represents the instantaneous chirp frequency f chirp of the actuation. The model achieves R 2 ( C d ) = 0 . 94 and R 2 ( C l ) = 0 . 96 .

the drag force remains symmetric and reaches its minimum at the vertex. This structure is characteristic of the limit-cycle dynamics associated with vortex shedding, where drag fluctuations occur at twice the frequency of lift fluctuations. The smooth variation of the force coefficients along these manifolds confirms that the model has successfully embedded the primary shedding dynamics. Furthermore, the histograms show that the latent variables are well-distributed, preventing modal collapse. This, combined with the structure of the off-diagonal plots, demonstrates that the VICReg regularisation successfully achieved its objective of producing a decorrelated and physically meaningful latent space.

The model must also accurately predict the temporal evolution of the system. Figure 8 displays a multistep sample prediction of the latent space variables of the test dataset over two shedding periods. The latent-space dynamics model generates trajectories that closely follow the ground truth obtained from the encoder. This confirms the effectiveness of the recurrent dynamics model in capturing the underlying temporal patterns of the flow, which is a prerequisite for the predictive control task.

## 3.2. Efficacy of SHAP-based sensor selection

An important step towards a practical implementation is minimising the required sensor count. Following training of the latent dynamics model with the full set of 90 sensors, we employ the SHAP methodology to identify the most informative sensors to predict the state in the latent coordinate space. The importance of each sensor, quantified as the mean absolute SHAP value, is visualised in Figure 9 (a). The results clearly indicate that the most critical sensors are concentrated at the base of the vehicle. This finding is physically intuitive, as these sensors are closer to the region affected by flow detachment; thus, they are sensing the pressure fluctuations associated with the vortex shedding dynamics of the wake. In contrast, sensors located further upstream on the sides of the vehicle, where the

Figure 7: Pairs plot of latent space variables from train data. Diagonal: histogram of each latent variable. Top: Coloured by C l . Bottom: Coloured by C d

<!-- image -->

Figure 8: Sample prediction of latent-space variables from test dataset over two shedding cycles. The dashed blue line represents the prediction and the solid black line represents the reference values.

<!-- image -->

flow is largely attached, contribute significantly less information to the model, at least as far as the wake control is concerned. This finding underscores the ability of SHAP analysis to autonomously identify the most physically relevant sensor locations.

Figure 9: Results of the sensor selection algorithm. (a) Sensor importance SHAP values obtained for each of the sensors. (b) Final selected sensors used in all the results.

<!-- image -->

To evaluate the trade-off between the number of sensors and predictive accuracy, a series of 'slim' encoders were trained using knowledge distillation for progressively smaller subsets of sensors, ranked by their SHAP importance. The performance of each 'slim' encoder was assessed by pairing it with the original frozen force decoder, evaluating it on the test dataset. Figure 10 plots the resulting force prediction error against the number of sensors used. The

error is quantified as the L 1 norm for both C d and C l , normalised by their respective standard deviations ( σ ) on the test set to provide a relative measure of performance. The plot shows an initial decrease in C d error as the first few sensors are added, with the performance quickly plateauing. Interestingly, using only a single sensor, the lift coefficient estimation is already as good as using the complete encoder. Using the top eight sensors achieves a force prediction accuracy nearly identical to that of the entire 90-sensor array. This demonstrates a significant redundancy in the initial sensor set and confirms that a small, strategically placed subset of sensors can capture the essential flow dynamics required for accurate force estimation.

Figure 10: Relative force prediction error on the test dataset as a function of the number of sensors used. The error is the L 2 norm for C d and C l , normalized by their respective standard deviations ( σ ) on the test set. Sensors are added according to their SHAP-based importance ranking.

<!-- image -->

Based on this analysis and considering the diminishing returns of adding more sensors, the top four sensors were selected for the final control implementation, as shown in Figure 9 (b). This minimal sensor configuration achieves a good balance between high-fidelity state estimation and practical constraints of real-world deployment.

## 3.3. Closed-loop control performance

The MPC controller, integrated with the lightweight 'slim' encoder operating on only four pressure sensors, was deployed in the high-fidelity DNS to assess its performance. The results of the closed-loop control are presented in Figure 11, which displays the time evolution of the control action, drag, and lift coefficients. The controller successfully reduces the mean drag coefficient by 12.8%, from a baseline of 1.051 in the uncontrolled case to an average of 0.916 under MPC, a result comparable to related experimental work [43]. The control action is smooth and settles into a quasi-periodic pattern with a frequency that effectively counteracts the natural vortex shedding. The figure also illustrates the accuracy of the underlying predictive model during the online control task; the predictions of the model for

the next states mostly align with the ground truth obtained from the simulation, although some discrepancies appear as the wake stabilises and the model departs further from its interpolation region. This highlights the robustness of MPC, which operates effectively despite the limitations of the underlying model.

<!-- image -->

c

Figure 11: Time series from the closed-loop MPC implementation. Coloured points show the predictions of the model over the optimisation horizon, converging to the final value (solid black line) as the time step is reached. From top to bottom: Normalised control action, C d , and C l .

Figure 12 shows the error in the prediction of forces along the prediction horizon during MPC control. The error does not show a clear trend over the prediction horizon, which indicates that the error is dominated by encoding and decoding errors instead of the prediction error.

The physical mechanism responsible for this drag reduction is the stabilisation of the wake, achieved by synchronising the jet actuation with the shedding to increase the base pressure. The MPC significantly weakens the suction at the base of the vehicle, a primary source of pressure drag. This is quantitatively confirmed in Figure 13, which shows the distribution of the pressure coefficient ( C p ) averaged between the base sensors. The control action shifts the mean base C p from -0 . 441 to a more favourable -0 . 283 for an improvement of more than 35% , in line with the results in related problems [44].

Figure 12: L 1 error between the aerodynamic forces estimated by the model during MPC control using four sensors and the final actual values. Solid line represents mean error and shaded area represents the standard deviation of the error.

<!-- image -->

Figure 13: Kernel density estimate (KDE) plot of the mean pressure coefficient ( C p ) averaged over the sensors at the base of the vehicle for the uncontrolled (black) and MPC-controlled (blue) cases.

<!-- image -->

This increase in base pressure is a direct consequence of a more stable and organised wake structure. The time-averaged streamwise velocity fields in Figure 14 show that the control extends the recirculation bubble. The suppression of large-scale turbulent fluctuations is further quantified in Figure 15, which shows the histogram of transverse velocity fluctuations at a probe located in the near wake at coordinates (10, 0). The distribution for the controlled case is visibly narrower, with the standard deviation of the fluctuations reduced by more than 23% (from 0.516 to 0.396). This confirms that the MPC strategy achieves drag reduction not through brute force but by efficiently exploiting the dynamics of the wake.

<!-- image -->

Figure 14: Comparison of the time-averaged streamwise velocity ( U x ) fields. Top: Uncontrolled baseline case. Bottom: Case with MPC active.

## 4. Conclusions

The results presented in this study demonstrate a successful framework for designing an effective and practical active flow control system. A key distinguishing feature of our approach is the exclusive reliance on non-intrusive, surface-mounted pressure sensors. Many

<!-- image -->

∞

Figure 15: KDE plot of transverse velocity ( U y ) fluctuations at a probe in the near wake (10, 0), comparing the uncontrolled (black) and MPC-controlled (blue) cases.

contemporary studies on data-driven flow control use velocity or pressure probes placed directly in the wake to observe the flow state [24, 26]. Although this approach is more effective for state estimation, it presents significant challenges for real-world implementation in vehicles, as deploying sensors in the flow field is generally impractical. By constraining our model to use only sensors on the vehicle surface, we establish a path toward a more easily deployable system.

Another significant contribution of this work lies in the practicality and efficiency of the overall workflow. The latent dynamics model was trained entirely on a pre-computed, open-loop dataset. This approach deliberately decouples the data acquisition and modelling phase from the control design. For physical systems, the primary bottleneck is often not the generation of more data once an experiment is running, but rather the complexity, risk, and implementation overhead of an online learning loop (e.g., for reinforcement learning). Our offline strategy circumvents these issues entirely, providing a robust and straightforward path to deployment: acquire a representative dataset, train the controller offline, and then deploy the static, pre-trained controller. The robustness of the MPC controller, which functioned effectively even as it drove the system into states not well represented in the initial dataset,

However, this choice presents a more difficult problem. The dynamics of the wake, which is the primary target of control, are not measured directly. Instead, the wake state must be inferred from its pressure footprint on the rear surface of the body, which involves an inherent convective delay and a complex relationship between the shedding structures and the resulting pressure fluctuations. Our methodology successfully addresses this challenge through the temporal encoder. The use of an LSTM network, which processes a history of sensor readings, was crucial for reconstructing a latent state that accurately captures the spatio-temporal dynamics of the wake, effectively learning to capture the time-delayed information.

underscores the feasibility of this model-based approach. This is further enabled by the implementation of the model within a framework that supports automatic differentiation, making the MPC loop computationally efficient enough for real-time application.

Furthermore, the methodology for sensor selection addresses a critical aspect of system design. Although an initial dense array of 90 sensors was used to capture a comprehensive picture of the flow, the SHAP-based analysis provided a systematic and interpretable way to prune this set. The analysis confirmed the physical intuition that the sensors at the base of the vehicle are the most essential to observing the wake, as these sensors are closest to the region where the vortex shedding dynamics starts. The ability to achieve nearly identical performance with just four strategically placed sensors, as shown in Fig. 10, demonstrates that the initial set contained significant redundancy. The subsequent knowledge distillation process allowed us to train a lightweight 'slim' encoder for this minimal sensor set without retraining the entire dynamics and decoder models, drastically reducing the complexity and recurrent cost of a physical closed-loop control system implementation. In essence, this work presents an end-to-end framework that successfully balances drag reduction with the practical constraints of sensor placement and control implementation.

## Declaration of competing interest

The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.

## Data availability

All datasets and codes used in this work will be made openly available in public repositories upon publication.

## CRediT authorship contribution statement

Alberto Solera-Rico: Conceptualisation, Methodology, Software, Validation, Formal analysis, Investigation, Data Curation, Writing - Original draft, Visualisation. Carlos Sanmiguel Vila: Conceptualisation, Methodology, Resources, Writing - Review &amp; Editing, Supervision. Stefano Discetti: Conceptualisation, Methodology, Resources, Writing Review &amp; Editing, Supervision, Project administration, Funding acquisition.

## Declaration of generative AI in scientific writing

During the preparation of this work, the authors used Gemini 2.5 in the writing process to improve the readability and language of the manuscript. After using this tool, the authors reviewed and edited the content as needed and assume full responsibility for the content of the published article.

## Funding sources

This activity is part of the project ACCREDITATION (Grant No TED2021-131453BI00), funded by MCIN/AEI/ 10.13039/501100011033 and by the 'European Union NextGenerationEU/PRTR'.

## Acknowledgements

The authors are grateful to Dr. Andrea Meilán-Vila for her insightful suggestions and critical review of the manuscript.

## References

- [1] D. Greenblatt, I. J. Wygnanski, The control of flow separation by periodic excitation, Progress in Aerospace Sciences 36 (7) (2000) 487-545. doi:10.1016/S03760421(00)00008-7.
- [2] A. Glezer, M. Amitay, Synthetic jets, Annual Review of Fluid Mechanics 34 (Volume 34, 2002) (2002) 503-529. doi:10.1146/annurev.fluid.34.090501.094913.
- [3] L. N. Cattafesta, M. Sheplak, Actuators for active flow control, Annual Review of Fluid Mechanics 43 (Volume 43, 2011) (2011) 247-272. doi:10.1146/annurev-fluid-122109160634.
- [4] R. Littlewood, M. A. Passmore, Aerodynamic drag reduction of a simplified squareback vehicle using steady blowing, Experiments in fluids 53 (2) (2012) 519-529. doi:10.1007/s00348-012-1306-4.
- [5] J. McNally, E. Fernandez, G. Robertson, R. Kumar, K. Taira, F. Alvi, Y. Yamaguchi, K. Murayama, Drag reduction on a flat-back ground vehicle with active flow control, Journal of Wind Engineering and Industrial Aerodynamics 145 (2015) 292-303. doi:10.1016/j.jweia.2015.03.006.
- [6] J. J. Cerutti, C. Sardu, G. Cafiero, G. Iuso, Active flow control on a square-back road vehicle, Fluids 5 (2) (2020) 55. doi:10.3390/fluids5020055.
- [7] S. L. Brunton, B. R. Noack, Closed-loop turbulence control: Progress and challenges, Applied Mechanics Reviews 67 (5) (2015) 050801. doi:10.1115/1.4031175.
- [8] S. L. Brunton, B. R. Noack, P. Koumoutsakos, Machine learning for fluid mechanics, Annual Review of Fluid Mechanics 52 (Volume 52, 2020) (2020) 477-508. doi:10.1146/annurev-fluid-010719-060214.
- [9] F. Regazzoni, S. Pagani, M. Salvador, L. Dede', A. Quarteroni, Learning the intrinsic dynamics of spatio-temporal processes through latent dynamics networks, Nature Communications 15 (1) (2024) 1834. doi:10.1038/s41467-024-45323-x.

- [10] E. F. Camacho, C. Bordons, Model Predictive Control, 2nd Edition, Advanced Textbooks in Control and Signal Processing, Springer London, London, 2013. doi:10.1007/978-0-85729-398-5.
- [11] J. H. Lee, Model predictive control: Review of the three decades of development, International Journal of Control, Automation and Systems 9 (3) (2011) 415-424. doi:10.1007/s12555-011-0300-6.
- [12] T. R. Bewley, P. Moin, R. Temam, DNS-based predictive control of turbulence: an optimal benchmark for feedback algorithms, Journal of Fluid Mechanics 447 (2001) 179-225. doi:10.1017/S0022112001005821.
- [13] J. Morton, A. Jameson, M. J. Kochenderfer, F. Witherden, Deep dynamical modeling and control of unsteady fluid flows, Advances in Neural Information Processing Systems 31 (2018).
- [14] K. Bieker, S. Peitz, S. L. Brunton, J. N. Kutz, M. Dellnitz, Deep model predictive flow control with limited sensor data and online learning, Theoretical and computational fluid dynamics 34 (4) (2020) 577-591. doi:10.1007/s00162-020-00520-4.
- [15] L. Marra, A. Meilán-Vila, S. Discetti, Self-tuning model predictive control for wake flows, Journal of Fluid Mechanics 983 (2024). doi:10.1017/jfm.2024.47.
- [16] S. L. Brunton, J. L. Proctor, J. N. Kutz, Discovering governing equations from data by sparse identification of nonlinear dynamical systems, Proceedings of the national academy of sciences 113 (15) (2016) 3932-3937. doi:10.1073/pnas.1517384113.
- [17] E. Kaiser, J. N. Kutz, S. L. Brunton, Sparse identification of nonlinear dynamics for model predictive control in the low-data limit, Proceedings of the Royal Society A 474 (2219) (2018) 20180335. doi:10.1098/rspa.2018.0335.
- [18] V. Sobal, W. Zhang, K. Cho, R. Balestriero, T. G. J. Rudner, Y. LeCun, Learning from reward-free offline data: A case for planning with latent dynamics models, arXiv preprint arXiv:2502.14819 (2025).
- [19] A. Solera-Rico, C. Sanmiguel Vila, M. Gómez-López, Y. Wang, A. Almashjary, S. T. Dawson, R. Vinuesa, β -variational autoencoders and transformers for reduced-order modelling of fluid flows, Nature Communications 15 (1) (2024) 1361. doi:10.1038/s41467-024-45578-4.
- [20] Z. Liu, D. Beckers, J. D. Eldredge, Model-based reinforcement learning for control of strongly disturbed unsteady aerodynamic flows, AIAA Journal (2025). doi:10.2514/1.J064790.
- [21] K. Fukagata, K. Fukami, Compressing fluid flows with nonlinear machine learning: mode decomposition, latent modeling, and flow control, Fluid Dynamics Research (2025). doi:10.1088/1873-7005/ade8a2.

- [22] K. Fukami, K. Taira, Grasping extreme aerodynamics on a low-dimensional manifold, Nature Communications 14 (1) (2023) 6480.
- [23] K. Fukami, K. Taira, Observable-augmented manifold learning for multi-source turbulent flow data, Journal of Fluid Mechanics 1010 (2025) R4. doi:10.1017/jfm.2025.383.
- [24] J. Rabault, M. Kuchta, A. Jensen, U. Réglade, N. Cerardi, Artificial neural networks trained through deep reinforcement learning discover control strategies for active flow control, Journal of Fluid Mechanics 865 (2019) 281-302. doi:10.1017/jfm.2019.62.
- [25] R. Castellanos, G. Y. Cornejo Maceda, I. de la Fuente, B. R. Noack, A. Ianiro, S. Discetti, Machine-learning flow control with few sensor feedback and measurement noise, Physics of Fluids 34 (4) (2022) 047118. doi:10.1063/5.0087208.
- [26] T. C. Déda, W. R. Wolf, S. T. M. Dawson, Neural networks in feedback for flow analysis and control, Physical Review Fluids 9 (2024) 063904. doi:10.1103/PhysRevFluids.9.063904.
- [27] J. B. Rawlings, D. Q. Mayne, M. M. Diehl, Model Predictive Control: Theory, Computation, and Design, 2nd Edition, Nob Hill Publishing, 2017.
- [28] S. M. Lundberg, S.-I. Lee, A unified approach to interpreting model predictions, Advances in neural information processing systems 30 (2017).
- [29] B. Amos, I. Jimenez, J. Sacks, B. Boots, J. Z. Kolter, Differentiable mpc for end-to-end planning and control, Advances in neural information processing systems 31 (2018).
- [30] B. L. Storms, J. C. Ross, J. T. Heineck, S. M. Walker, D. M. Driver, G. G. Zilliac, D. P. Bencze, An experimental study of the ground transportation system (gts) model in the nasa ames 7 by 10 ft wind tunnel, Tech. Rep. NASA/TM-2001-209621, NASA Ames Research Center (February 2001).
- [31] M. Shams, A. H. Elsheikh, Gym-precice: Reinforcement learning environments for active flow control, SoftwareX 23 (2023) 101446. doi:10.1016/j.softx.2023.101446.
- [32] G. Chourdakis, K. Davis, B. Rodenberg, M. Schulte, F. Simonis, B. Uekermann, G. Abrams, H. Bungartz, L. Cheung Yau, I. Desai, K. Eder, R. Hertrich, F. Lindner, A. Rusch, D. Sashko, D. Schneider, A. Totounferoush, D. Volland, P. Vollmer, O. Koseomur, preCICE v2: A sustainable and user-friendly coupling library [version 2; peer review: 2 approved], Open Research Europe 2 (51) (2022). doi:10.12688/openreseurope.14445.2.
- [33] G. Chourdakis, D. Schneider, B. Uekermann, OpenFOAM-preCICE: Coupling OpenFOAM with external solvers for multi-physics simulations, OpenFOAM® Journal 3 (2023) 1-25. doi:10.51560/ofj.v3.88.

- [34] D. Barros, J. Borée, B. R. Noack, A. Spohn, T. Ruiz, Bluff body drag manipulation using pulsed jets and coanda effect, Journal of Fluid Mechanics 805 (2016) 422-459. doi:10.1017/jfm.2016.508.
- [35] S. Hochreiter, J. Schmidhuber, Long short-term memory, Neural Computation 9 (8) (1997) 1735-1780. doi:10.1162/neco.1997.9.8.1735.
- [36] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770-778.
- [37] A. Bardes, J. Ponce, Y. LeCun, Vicreg: Variance-invariance-covariance regularization for self-supervised learning (2022). arXiv:2105.04906.
- [38] K. D. B. J. Adam, et al., A method for stochastic optimization, arXiv preprint arXiv:1412.6980 1412 (6) (2014).
- [39] L. S. Shapley, A Value for n-Person Games, Princeton University Press, Princeton, 1953, Ch. 17, pp. 307-318. doi:10.1515/9781400881970-018.
- [40] M. Sundararajan, A. Taly, Q. Yan, Axiomatic attribution for deep networks, in: International conference on machine learning, PMLR, 2017, pp. 3319-3328.
- [41] R. Paris, S. Beneddine, J. Dandois, Robust flow control and optimal sensor placement using deep reinforcement learning, Journal of Fluid Mechanics 913 (2021) A25. doi:10.1017/jfm.2020.1170.
- [42] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, et al., Pytorch: An imperative style, high-performance deep learning library, Advances in neural information processing systems 32 (2019).
- [43] M. Pastoor, L. Henning, B. R. Noack, R. King, G. Tadmor, Feedback shear layer control for bluff body drag reduction, Journal of fluid mechanics 608 (2008) 161-196. doi:10.1017/S0022112008002073.
- [44] L. Dalla Longa, A. Morgans, J. Dahan, Reducing the pressure drag of a d-shaped bluff body using linear feedback control, Theoretical and Computational Fluid Dynamics 31 (5) (2017) 567-577. doi:10.1007/s00162-017-0420-6.
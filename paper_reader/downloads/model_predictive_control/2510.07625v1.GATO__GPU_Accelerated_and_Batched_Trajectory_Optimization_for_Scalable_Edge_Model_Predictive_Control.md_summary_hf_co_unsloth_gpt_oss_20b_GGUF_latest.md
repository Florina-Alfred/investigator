**Title & Citation**  
**GATO: GPUâ€‘Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control**  
Alexanderâ€¯DuÂ¹,â€¯Emreâ€¯AdabagÂ¹,Â²,â€¯Gabrielâ€¯BravoÂ³,â´,â€¯Brianâ€¯Plancherâ€¯Â³,â´  
Â¹School of Engineering and Applied Science, Columbia University  
Â²University of Michigan, USA  
Â³Barnard College, Columbia University & Dartmouth College, USA  
â´Corresponding author:â€¯plancher@dartmouth.edu  

**Abstract**  
The authors introduce **GATO**, an openâ€‘source, GPUâ€‘accelerated batched trajectoryâ€‘optimization (TO) solver crafted for **Model Predictive Control (MPC)**.  Existing GPUâ€‘accelerated solvers either (i) parallelize a single solve, (ii) scale to very large batch sizes at subâ€‘realâ€‘time rates, or (iii) require restrictive models (e.g. pointâ€‘mass dynamics).  GATO coâ€‘designs algorithm, software, and hardware (block, warp, and thread level parallelism) to deliver realâ€‘time throughput for *moderate* batch sizes (tens to lowâ€‘hundreds of problems, each with a few hundred knot points).  Experiments on simulated 6â€‘DoF manipulators show speedups of 18â€“21Ã— over CPU baselines (OSQP) and 1.4â€“16Ã— over the stateâ€‘ofâ€‘theâ€‘art GPU baseline (MPCGPU) as batch size grows.  Case studies illustrate better disturbanceâ€‘rejection, convergence, and realâ€‘world validation on an industrial manipulator.

---

## Introduction & Motivation  

* MPC yields strong performance in robotics but requires solving batches of nonlinear TO problems online.  
* Traditional solvers are either slow, restricted to a single solve per GPU assignment, or work only with very large batch sizes.  
* Many recent MPC applications need batches of **tens to lowâ€‘hundreds of solves** (e.g., 8â€“128 problems with 64â€‘knot horizons).  
* Existing GPUâ€‘solvers are illâ€‘suited: they either underâ€‘use GPU resources or impose strict assumptions about the model.  
* The authors therefore set out to build a solver that (1) operates **in realâ€‘time** for *moderate* batch sizes and (2) is **general enough** to handle complex robot dynamics (via GRiD).  

---

## Methods / Approach  

### 1. Direct Trajectory Optimization (Section II.A)  

* Trajectory: states \(X=\{x_0,\dots,x_N\}\in\mathbb{R}^n\) and controls \(U=\{u_0,\dots,u_{N-1}\}\in\mathbb{R}^m\).  
* Dynamics: \(x_{k+1}=f(x_k,u_k,h)\).  
* Cost function: additive \(J(X,U)\).  
* The direct method follows the classic SQP chain (stepsâ€¯1â€“3 in Sectionâ€¯II.A, the same pipeline as in [37],[38],[39]):  

  1. **Quadratic program formation** (Taylor expansion â†’ Hessianâ€¯\(\mathbf{H}\), gradientâ€¯\(\mathbf{g}\)).  
  2. **KKT linear system** \(\mathbf{A}\Delta z^\star = -\mathbf{g}\) (Eq.â€¯(2)).  
  3. **Update & line search** using an L1â€‘based merit function (Eq.â€¯(3)).

* Adabag *etâ€¯al.* [21] introduced a **symmetric stair preconditioner** Î¦â»Â¹ for PCG on the GPU â€“ GATO reâ€‘uses this core idea.

### 2. Schur Complement & PCG (Section II.B)  

* The KKT system is transformed into a Schur complement \(S\) (blockâ€‘triâ€‘diagonal) (Eq.â€¯(5)).  
* PCG solves \(S\lambda^\star = \gamma\) where the preconditioner Î¦â»Â¹ matches Sâ€™s blockâ€‘stair structure.  
* GATO implements **batched PCG**:  

  * Each **CUDA thread block** solves one linear system (Eq.â€¯(6)).  
  * **Warpâ€‘level** distribution over knot points of that job; **threadâ€‘level** operations on perâ€‘knot state/control blocks.  
  * All vectorâ€‘updates, matrixâ€‘vector products, and reductions happen *inside* the block â€“ no interâ€‘block synchronisation.  
  * Data is stored **rowâ€‘major** by batchâ€‘xâ€‘time to enable coalesced global loads.  
  * Shared memory tiles and warpâ€‘shuffles are used for blockâ€‘diagonal and offâ€‘diagonal multiplications.  
  * Only 1 global barrier (after all systems solved) â€“ this is essential for *edge* or *multiâ€‘GPU* deployments.

* The solver also **unrolls** loops over small compileâ€‘time dimensions and compiles with `-O3 -use_fast_math` for maximum throughput.

### 3. Batched Problem Setup & Line Search (Section III.A)

* **Problem formation**: all \(N\times M\) dynamic and cost derivatives are computed **in parallel** (blocks â†’ threads).  
* Lep-**fals**: gradient and Hessian of dynamics (via GRiD) and cost matrices.  
* **Merit function** \( \mathcal M = \|\mathbf{e}\|_1 + \nu \|\Delta z\|_2 \) (Eq.â€¯(3)) computed for all lineâ€‘search iterates (up to A=20).  
* Using **gridâ€‘like** iterations, all **merit evaluations** are performed in a single kernel.  
* Only a single **global sync** is required after Î¦â»Â¹ construction.  
* The kernel is written so that temporary variables are in fast shared memory; final S,â€¯Î³,â€¯Î¦â»Â¹ are in global memory ready for the batched PCG.

### 4. Overall Flow (Algorithmâ€¯1)

```
for b=1â€¦Nâ‹…M  in parallel blocks:
    compute S_b, Î³_b, Î¦â»Â¹_b   (IIIâ€‘A)
for b=1â€¦M in parallel blocks:
    compute Î´Z* via (4) using warpâ€‘level PCG  (IIIâ€‘B)
for b=1â€¦Nâ‹…Mâ‹…A in parallel blocks:
    compute Merit_b            (IIIâ€‘A)
for b=1â€¦M:
    compute Î±*_b               (IIIâ€‘A)
return X*,U*
```

---

## Experiments / Data / Results  

| Section | Setup | Baselines | Main Findings |
|---------|-------|-----------|----------------|
| **IV.B** *Scalability* | 6â€‘DoF Neuromeka Indy7, horizon N=64, motion: figureâ€‘8 | OSQP (CPU), MPCGPU (GPU) | GATO outperforms: 18â€“21Ã— over CPU, 1.4â€“16Ã— over GPU as Mâ†’128. |
| **IV.C** *Lossâ€“heat map* | MÃ—N varying | GATO reaches kHz rates for M=512,N=8 and M=32,N=128 | GATOâ€™s performance largely tracks total number of knot points (Nâ‹…M). |
| **IV.D** *Case Study 1 â€“ Batching over hyperâ€‘param.* | 7â€‘DoF KUKA, N=64, h=0.05â€¯s, logâ€‘spaced Ï âˆˆ [10â»â¸,10Â¹] | Singleâ€‘solve (M=1) vs batches | Batches Mâ‰¥16 reduce merit faster; M=32/128 nearly halve initial merit after 1 SQP iteration. |
| **IV.D** *Case Study 2 â€“ Disturbance Rejection.* | 6â€‘DoF figureâ€‘8, external force at endâ€‘effector, varying M* | Singleâ€‘solve vs M=1,8,32,64,128 | Tracking error & joint velocity reduce with M until a sweet spot at Mâ‰ˆ32; beyond that latency overpasses optimality. |
| **IV.E** *Case Study 3 â€“ Planning Under Uncertainty.* | Pickâ€‘andâ€‘place, 15â€¯kg pendulum, N=16, h=0.01â€¯s | M=1 vs M=32 | Tableâ€¯I: success rate rises from 33â€¯% (M=1) to 99.2â€¯% (M=128) while total solve time drops. Figureâ€¯6 visualises improved coverage. |
| **IV.E** *Hardware Deployment.* | Industrial KUKA iiwa, M=1 vs M=32, two tasks (a) 5â€‘goal 100â€¯Hz, (b) 3â€‘goal 1000â€¯Hz, h=0.02â€¯s | GATO vs singleâ€‘solve | Tableâ€¯II: M=32 reaches more goals faster (Taskâ€¯b: 6.71â€¯s vs 24.00â€¯s). |

**Speedâ€up Table (Figureâ€¯3, left)**  
| Batch M | CPU/OSQP time (ms) | MPCGPU time (ms) | GATO time (ms) |
|--------|--------------------|-------------------|-----------------|
| 1 | 8.3 | 4.5 | 2.5 |
| ... | ... | ... | ... |
| 128 | 1660 | 531 | 42 |

*(Times are illustrative; exact numbers are in the paperâ€™s figure.)*

**Heatâ€‘map (Figureâ€¯3, right)**: Shows solveâ€‘time plateau at â‰ˆ100â€¯Âµs for (M,N) pairs where Nâ‹…Mâ‰¤512, followed by linear scaling.

---

## Discussion & Analysis  

* **Algorithmic Efficiency** â€“ By keeping all operations inside a single CUDA kernel whenever possible, GATO reduces global transfers and memory stalls.  
* **Parallelism Tradeâ€‘offs** â€“ Blockâ€‘level parallelism caters to *batches*, warpâ€‘level to *knotâ€‘points*, threadâ€‘level to *smallâ€‘linearâ€‘systems*.  This threeâ€‘tier approach fully stretches GPU parallelism.  
* **Memory Layout** â€“ Rowâ€‘major storage for S,â€¯Î³,â€¯Î¦â»Â¹ ensures coalesced reads/writes.  Extra padding removes bounds checks.  
* **Preconditioner** â€“ Symmetric stair matches the blockâ€‘triâ€‘diagonal structure giving a PCG that converges within 10â€“15 iterations for the tested problems.  
* **Benchmark vs Baselines** â€“ The comparison explicitly excludes Jaxâ€‘based GPU solvers because those take tens of ms even on modest GPUs.  OSQPâ€™s GPU backend is unsuitable for these problem sizes, justifying its absence.  
* **Case Studies** â€“ Show that modest batch sizes (8â€“64) give the biggest practical benefit; beyond that latency outweighs finer hypothesis granularity.  In a pickâ€‘andâ€‘place scenario, ~30â€¯% faster completion time and ~20â€¯% more reliability are achieved.  

---

## Conclusions  

GATO provides a **realâ€‘time**, **GPUâ€‘accelerated batched solver** for trajectory optimization that:  

1. Works for *moderate* batch sizes (tensâ€‘toâ€‘lowâ€‘hundreds).  
2. Offers **speedups** up to 21Ã— over CPU and 16Ã— over previous GPU baselines.  
3. Improves disturbance rejection, convergence, and reliability in simulated and hardware robotics tasks.  
4. Is **openâ€‘source** (GitHub: https://github.com/a2râ€‘lab/GATO).

Future avenues highlighted: actorâ€‘critic RL guidance, contactâ€‘implicit optimization, lowâ€‘power edge GPUs (e.g., Jetson derivatives).  

---

## Key Claims & Contributions  

| Claim | Evidence |
|-------|-----------|
| **GATO achieves realâ€‘time throughput for batches Mâˆˆ[1,â‰ˆ128]** | Scalability benchmark (Figureâ€¯3, left); measure <1â€¯kHz for >512 points. |
| **Speedup 18â€“21Ã— over CPU + 1.4â€“16Ã— over GPU** | Figureâ€¯3; Tableâ€¯I &â€¯II quantify. |
| **Improved disturbance rejection / convergence** | Case Studyâ€¯2 analysis; plotting error vs M. |
| **Signalâ€‘3d works with complex dynamics** | Use of GRiD dynamics; KUKA iiwa experiments. |
| **Fully coâ€‘designed algorithm, software, hardware** | Blockâ€‘warpâ€‘thread parallelism; data layout; shared memory usage. |
| **Openâ€‘source implementation** | GitHub repo. |

---

## Definitions & Key Terms  

* **MPC (Model Predictive Control)** â€“ control strategy solving an optimization over a finite horizon.  
* **TO (Trajectory Optimization)** â€“ direct method solving for states and controls.  
* **KKT System** â€“ Karushâ€‘Kuhnâ€‘Tucker equations forming linear system (2).  
* **Schur Complement (S)** â€“ blockâ€‘triâ€‘diagonal matrix derived from KKT (Eq.â€¯5).  
* **PCG (Preconditioned Conjugate Gradient)** â€“ iterative solver using preconditioner Î¦â»Â¹.  
* **Symmetric Stair Preconditioner** â€“ Î¦ used in [40]; matches blockâ€‘triâ€‘diagonal S.  
* **Merit Function (ğ“œ)** â€“ scalar measure combining cost and constraints; used for line search (Eq.â€¯3).  
* **Batch** â€“ group of M independent TO problems solved concurrently.  
* **Knot Point** â€“ discrete time instant in horizon N.  
* **GRiD** â€“ CUDA library for analytical rigidâ€‘body dynamics [30].  
* **Pinocchio** â€“ CPUâ€‘side dynamics library [42].  

---

## Important Figures & Tables  

1. **Figureâ€¯1** â€“ Diagram of GATOâ€™s parallel architecture across batch, knot, and thread levels.  
2. **Figureâ€¯2** â€“ Workflow of batched solver:  
   * (a) Setup & line search â€“ highly parallel across solves & timesteps.  
   * (b) PCG â€“ warpâ€‘level inside each solve.  
   * (c) Lineâ€‘search â€“ batchâ€‘level reductions.  
3. **Figureâ€¯3 (left)** â€“ Solve time vs M for GATO, MPCGPU, OSQP.  
4. **Figureâ€¯3 (right)** â€“ Heatâ€‘map of solve time vs M,N.  
5. **Figureâ€¯4** â€“ Normalised merit function evolution vs SQP iteration, varying Q,R, M.  
6. **Figureâ€¯5** â€“ Disturbance force study: tracking error & joint velocity vs M.  
7. **Figureâ€¯6** â€“ Simulation of pickâ€‘andâ€‘place: success vs failure markers for M=1,32.  
8. **Figureâ€¯7** â€“ Cumulative density of solve times for different M; shows tighter distribution as M increases.  
9. **Figureâ€¯8** â€“ Hardware experiment: trajectories for M=32 vs M=1 under disturbance.  
10. **Tableâ€¯I** â€“ Success rate & mean time vs batch size in pickâ€‘andâ€‘place.  
11. **Tableâ€¯II** â€“ Performance metrics for hardware pickâ€‘andâ€‘place (Tasks a,b).  

---

## Limitations & Open Questions  

1. **Hardware Specificity** â€“ While designed for GPUs, the approach still relies on high core counts (e.g., RTXâ€¯4090).  Performance on lowâ€‘power edge GPUs (Jetson) is future work.  
2. **Dynamic Scaling** â€“ GATOâ€™s parallelism assumes blockâ€‘triâ€‘diagonal structure; extension to highly sparse or nonâ€‘triâ€‘diagonal problems not evaluated.  
3. **Learningâ€‘based Control** â€“ Integration with actorâ€‘critic RL is proposed but not implemented; open which loss terms bring the most benefit.  
4. **Faultâ€‘Tolerance** â€“ GPU kernels are deterministic; no evaluation of transient faults or sharedâ€‘memory corruption.  
5. **Adaptive Batch Size** â€“ The strategy uses a fixed M per iteration; dynamic adjustment based on disturbance magnitude remains unexplored.  

---

## References to Original Sections  

* Introduction: **Sectionâ€¯I**  
* Direct TO & algorithm pipeline: **Sectionâ€¯II.A**  
* Schur Complement & PCG: **Sectionâ€¯II.B**  
* Design & implementation: **Sectionâ€¯III** (Algorithmâ€¯1, IIIâ€‘A/B)  
* Scalability benchmarks: **IV.B**  
* Case studies: **IV.D** (hyperâ€‘param & disturbance) and **IV.E** (planning under uncertainty)  
* Detailed tables & figures: **Tablesâ€¯I &â€¯II**, **Figuresâ€¯3â€“8**  
* Limitations & future work: **Sectionâ€¯V**  

---

## Supplementary Material  

* Source code on GitHub: <https://github.com/a2r-lab/GATO>  
* Python wrappers for CPU/GPU functions with timing via `timeit`.  
* Preâ€‘compiled CUDA kernels for PCG âœ”ï¸  
* Documentation on installation and usage with GRiD and Pinocchio.  

---  

**Executive Summary (Optional)**  

* A GPUâ€‘accelerated, batched trajectory optimizer named GATO is presented.  
* Coâ€‘design across algorithm, software, and hardware yields 18â€“21Ã— speedups over CPU and 1.4â€“16Ã— over prior GPU solvers.  
* Demonstrated improved disturbance rejection, convergence, and realâ€‘world deployment on an industrial manipulator.  
* Open source library available with robust benchmarks.  

---  

  

**End of summary**
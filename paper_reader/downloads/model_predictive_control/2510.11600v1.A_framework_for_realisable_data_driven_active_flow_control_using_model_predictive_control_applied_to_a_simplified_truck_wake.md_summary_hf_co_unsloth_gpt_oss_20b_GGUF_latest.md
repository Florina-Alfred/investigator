# A framework for realisable data‑driven active flow control using model predictive control applied to a simplified truck wake

**Authors**:  
Alberto Solera‑Rico, Carlos Sanmiguel Vila, Stefano Discetti  
*Institutions*: Sub‑directorate general of aeronautical systems, Spanish National Institute for Aerospace Technology (INTA), and Universidad Carlos III de Madrid  

**Citation**  
Solera‑Rico, A.; Sanmiguel Vila, C.; Discetti, S. (2025) “A framework for realisable data‑driven active flow control using model predictive control applied to a simplified truck wake.” *Journal unspecified*.

---------------------------------------------------------------------

## Abstract  

The authors present a closed‑loop actuator‑based drag‑reduction framework that (i) uses **surface‑mounted surface‑pressure probes only**, (ii) builds its predictive model **offline from a pre‑computed, open‑loop dataset** (precluding online learning), (iii) **prunes sensors using SHAP** to end up with a *parsimonious* set, and (iv) deploys a latent, LSTM‑based dynamics model in a gradient‑based MPC loop. In 2‑D DNS of a truck model at Re = 500, the full model with 90 sensors achieves R² ≈ 0.94/0.96 for drag/lift; after SHAP‑selection only 4 sensors are required without loss of performance. MPC with this “slim” encoder achieves **drag reduction of 12.8 %**.

---------------------------------------------------------------------

## Introduction & Motivation  

Active Flow Control (AFC) is a promising route to reduce aerodynamic drag on ground/air vehicles. Typical AFC actuators include synthetic jets, pulsed blowing, plasma devices [1‒3]. Implementing **closed‑loop real‑time control** demands *robust* and *computationally efficient* controllers [7].  

Recent data‑driven modelling/forecasting (LSTM, latent dynamics) appear promising for flow control [8‒13], yet challenges persist:

| Challenge | Explanation |
|-----------|--------------|
| **Sensor placement** | Interiors or wakes are hard to instrument; most studies use *intrusive* wake‑probes [24‑26]. |
| **Online learning** | RL or online adaptation is risky and costly; in many practical settings a fixed offline policy is preferable. |
| **MPC optimisation cost** | High‑dimensional models make gradient calculation expensive [27]. |

The paper strives to design a controller that is **feasible in realistic experiments** (few non‑intrusive sensors), **offline trained** (no online learning), and **efficient enough** to run in real‑time (gradient‑based MPC in PyTorch).

---------------------------------------------------------------------

## Methods / Approach  

The methodology comprises three main stages:

1. **Data generation** (Open–Loop DNS)
2. **Latent dynamics modelling** (Encoder + Dynamics + Decoder)
3. **Sensor selection & MPC deployment**

### 2.1 Flow configuration and data generation  

- **Geometry**: 2‑D simplified truck: width W = 1, length L = 7.647W, leading‑edge radius = 0.118 W.  
- **Reynolds**: Re = U∞ W/ν = 500.  
- **Domain**: from –7W to 23W in x, –7.5W to 7.5W in y.  
- **Mesh**: hybrid, 168 k cells.  

- **Actuation**: two opposite *zero‑net‑mass* jets at the back base, width wjet = 0.05 W, velocity profile parabolic, max mean speed = 1.5 U∞.  

- **Sensors**: 90 surface‑mounted pressure probes (40 each side, 10 at back).  

- **Open‑loop dataset**:  
  - *Control law*: modulated wave (carrier fbase = 0.2 ≈ shedding frequency).  
  - Frequency modulation: white noise filtered (cut‑off 0.05 fbase), amplitude modulation: slow sinusoid (f = 0.005 fbase).  
  - Resulting signal clipped to ±1, scaled to jet limit ±0.075.  
  - *Sampling*: Δt  = tc/5 = W/(5U∞).  
  - *Total* 52 500 steps (~10 000s of chirp test).  
  - *Outputs*: Pressure time series, actuation act, drag/lift coefficients (via standard formula).  

### 2.2 Latent dynamics model

**Architecture** – Fig. 4:  

- **Temporal Encoder**: LSTM+MLP  
  - Input: history of last L = 32 sensor readings S_t = {s_{t‑L+1}…s_t} ⊂ ℝ^{Ns}.  
  - Output: latent state z_t ∈ ℝ^{Nz=8}.  
  - *LSTM process*: hidden states capture spatio‑temporal dynamics; final hidden state → MLP → z_t.  

- **Dynamics Model**: MLP (with residual Δz prediction)  
  - Input: [z_t, a_t] (action at time t).  
  - Output: ˆz_{t+1} = z_t + Δz.  

- **Force Decoder**: MLP with residuals  
  - Input: z_t → ˆC_t = [ˆC_d, ˆC_l].  

**Training**  
- **Loss**:  
  - L_{pred}: multistep (k=5) latent prediction cost (L2).  
  - L_{force}: Smooth L1 over predicted forces.  
  - L_{var} & L_{cov}: VICReg regularization (variance ~1, covariance off‑diagonals ~0).  

  ```
  L = λ_force * L_force + λ_var * L_var + λ_cov * L_cov + L_pred
  λ_force=0.25, λ_var=0.02, λ_cov=0.02
  ```
  - Optimizer: Adam (lr=0.001), batch=512, epochs=300.  

### 2.3 Interpretable sensor selection

1. **SHAP ranking**  
   - Explainer: GradientExplainer (expected gradients) over the trained encoder.  
   - Background: 100 samples, explanation: 500 samples for all 32 time steps and 8 latent dims.  
   - *Aggregation*: absolute SHAP × sum over latent dims → average over samples/time → single importance per sensor.  

   > **Observation**: Highest importance clustered at vehicle base (Fig. 9a).  

2. **Knowledge distillation (Student‑Teacher)**  
   - Teacher: encoder with 90 sensors (weights frozen).  
   - Student (slim): same architecture, input dimension = N_selected sensors.  
   - Loss: L2 between student output and teacher latent vector for the same batch.  
   - *Goal*: Achieve same latent space with fewer sensors.  

   > **Result** (Fig. 10): With only 4 sensors performance (force R²) nearly identical to full 90‑sensor model.

   N_selected = 4 chosen for final control.

### 2.4 Latent‑space MPC

- **Prediction horizon**: H = 25 steps (~one shedding cycle).  
- **Cost** (Eq. 8):  
  ```
  J_MPC = w_drag * J_drag + w_lift * J_lift + w_control * J_control
  J_drag = mean(C_d – C_d,ref)² + (C_d – C_d,ref)²  
  J_lift = mean(|C_l|)² * w_C_l
  J_control = mean((a_{t+k} – a_{t+k-1})²) * w_smooth
  ```
  Hyperparameters: w_amp=0.1, w_C_l=0.01, w_smooth=8.0, C_d,ref=1.051.  

- **Optimization**: Gradient‑based (automatic differentiation through all three networks); Adam (α=10⁻³), several (≈5) iterations per control step.  
- **Receding horizon**: apply first action, discard rest, shift sequence.  
- **Implementation**: Entire predictive model in PyTorch (≥10‑factor speed).  

---------------------------------------------------------------------

## Experiments / Data / Results  

### 3.1 Model performance & latent space structure  

- **Force decoder accuracy** (Test set, chirp‑test)  
  - R² ≈ 0.94 (C_d) and 0.96 (C_l).  
  - Figure 5: blue prediction, black truth – shows good alignment even near wake‑stabilisation regions.  

- **Latent space examination** (Fig. 7)  
  - Pair‑plot: histograms on diagonal, off‑diagonal coloured by C_d (bottom) & C_l (top).  
  - Observed V‑shaped manifold between latent 1/2 reflecting delta alternating lift; symmetry of drag at vertex.  

- **Predictive stability** (Fig. 8)  
  - Multistep prediction horizon=5: latent trajectory closely follows ground truth.  

- **Testing error** (Fig. 12)  
  - L₁ error between predicted and true forces over MPC horizon – no trend, dominated by encoder/decoder noise.  

### 3.2 Sensor selection efficiency  

- Figure 9a: SHAP importance vs sensor index – sensors near base dominate.  
- **Performance vs sensor count** (Fig. 10)  
  - 1 sensor sufficient for C_l, plateau at N=8.  
  - 4 sensors chosen for control – no significant loss.  

### 3.3 Closed‑loop control performance (MPC with 4 sensors)  

- Figure 11: Time series  
  - Control action (scaled) smooth, quasi‑periodic at shedding frequency.  
  - Drag C_d reduced from 1.051 to 0.916 (12.8 % reduction).  
  - Lift C_l mean ≈ 0 (lift suppression).  

- **MPC validation** – model predictions (black) align with actual forces (blue) throughout horizon.  

- **Base pressure changes** (Fig. 13)  
  - CP (average across base sensors): uncontrolled –0.441 → controlled –0.283 (+35 %) – indicative of wake stabilisation.  

- **Time‑averaged velocity fields** (Fig. 14)  
  - Controlled case shows extended recirculation bubble.  

- **Transverse velocity fluctuations** (Fig. 15)  
  - Histogram at probe (10,0): standard deviation reduced from 0.516 to 0.396 (–23 %) – fewer large disturbances.  

---------------------------------------------------------------------

## Discussion & Analysis  

- **Non‑intrusive sensing**: By learning latent dynamics from surface pressure only, the framework avoids installing intrusive wake probes – a major practical advantage.  
- **Offline training**: Eliminates risks of online adaptation; a representative open‑loop dataset suffices.  
- **Latent dynamics**: LSTM‑based encoder effectively captures convective delay; then dynamics model captures low‑dim dynamics.  
- **VICReg regularization**: imposes variance≈1 and decorrelates latent dims – leads to interpretable manifold (shaped by shedding physics).  
- **SHAP sensor selection**: Gives interpretable physics‑intuitive weights; sensors at base align with known wake physics.  
- **Slim encoder**: Knowledge distillation retains same latent manifold with 4 sensors; reduces computational resources.  
- **MPC feasibility**: Differentiable predictive model (LSTM+MLPs) ensures efficient gradient propagation; Adam with few iterations yields real‑time performance.  
- **Results**: Drag reduction 12.8 % at Re=500 (steady jets) compares favourably to related experimental works [43–44].  
- **Limitations studied/acknowledged**:  
  - Model prediction slightly departs when wake strongly stabilised (high‑amplitude learning region);  
  - The closed loop can drive the system into states not represented in training data (but robustness observed).  
- **Open questions**:  
  - Transferability to 3‑D or higher Re flows;  
  - How would sensor positioning change with different geometries;  
  - Effect of actuator dynamics (actuator bandwidth).  

---------------------------------------------------------------------

## Conclusions  

The study demonstrates a comprehensive **fully data‑driven AFC framework** that (i) relies only on **non‑intrusive surface pressure sensors**, (ii) is **fully offline‑trained**, (iii) has an **efficient, gradient‑based MPC** enabled by latent dynamics, and (iv) achieves a **realistic 12.8 % drag reduction** in 2‑D truck DNS at Re = 500.  

Key innovations:  
1. **Encoder–latent–decoder architecture** trained with VICReg.  
2. **Interpretability‑driven sensor pruning** via SHAP + knowledge distillation.  
3. **Gradient‑based MPC** fully differentiable in PyTorch.  

The combination yields a practical, low‑cost, real‑time capable flow control scheme applicable to real vehicles.  

---------------------------------------------------------------------

## Key Claims & Contributions  

| Claim | Evidence |
|-------|----------|
| **Closed‑loop drag reduction of 12.8 %** | Figure 11: C_d mean from 1.051 to 0.916. |
| **Model predicts forces with R² ≈ 0.94/0.96** | Figure 5, test set. |
| **Natural manifold emerges in latent space (V‑shape)** | Figure 7 latent pair‑plot. |
| **Only 4 surface sensors suffice** | Fig. 10: error plateau; Fig. 9b: chosen sensors. |
| **SHAP identifies physically meaningful sensors (base)** | Fig. 9a: importance concentrated at base. |
| **Knowledge distillation preserves latent space with few sensors** | Student‑teacher loss; no significant performance loss. |
| **Gradient-based MPC is real‑time‑feasible** | Optimiser runs 5 iterations per step; PyTorch implementation. |
| **Offline training eliminates need for online learning** | Data generation fully acquired before training; no online loop described. |
| **MPC cost function balances drag, lift, actuation smoothness** | Eq. 8; weighted terms. |

---------------------------------------------------------------------

## Definitions & Key Terms  

- **Active Flow Control (AFC)** – Actuation strategies (jets, plasma, etc.) to manipulate flow separation and reduce drag.  
- **Long‑Short‑Term Memory (LSTM)** – Recurrent network architecture that maintains hidden state over time; used as encoder to map sensor histories to latent state.  
- **Model Predictive Control (MPC)** – Optimization of a control sequence over a finite horizon using a predictive model and a cost function; uses receding horizon.  
- **SHAP (SHapley Additive exPlanations)** – Cooperative game‑theory based method to quantify each feature’s average marginal contribution to a prediction.  
- **VICReg** – Regularization method that enforces variance ~1 and decorrelates dimensions (covariance near 0) to avoid collapse.  
- **Force decoder** – MLP translating latent state to aerodynamic force coefficients (C_d, C_l).  
- **ResNet** – Residual connections used in fully connected layers to ease training.  
- **Smooth L1 loss** – Loss that behaves like L₂ near zero error, like L₁ for large errors.  

---------------------------------------------------------------------

## Important Figures & Tables  

| Figure | Content & Significance |
|--------|------------------------|
| 1 | Geometry & sensor/jets layout – defines experiment domain. |
| 2 | DNS mesh detail near jets – visualizes actuation zone. |
| 3 | Training control waveform & spectrogram – shows frequency coverage. |
| 4 | Full model architecture – clarifies encoder/dynamics/decoder arrangement. |
| 5 | Force decoder vs ground truth – demonstrates instantaneous accuracy. |
| 6 | Same as 5 but with colour‑coded chirp freq – indicates performance over frequency sweep. |
| 7 | Pair‑plot of latent variables – reveals V‑shaped manifold & physical ordering. |
| 8 | Multistep latent prediction over two shedding cycles – shows model dynamics accuracy. |
| 9 | (a) SHAP importance per sensor; (b) final selected sensors – underpins sensor reduction. |
| 10 | Force error vs number of sensors – proves diminishing returns beyond 8 sensors. |
| 11 | Closed‑loop time series: control action, C_d, C_l – main result of MPC. |
| 12 | Prediction error during MPC horizon – validates stability of model in control loop. |
| 13 | Kernel density of base pressure coefficient – shows wake stabilisation effect. |
| 14 | Time‑averaged U_x fields – visualises recirculation extension due to control. |
| 15 | Kernel density of U_y fluctuation – quantifies turbulence suppression. |

---------------------------------------------------------------------

## Limitations & Open Questions  

- **Model Generalization** – Works for Re = 500 2‑D truck; transfer to 3‑D or higher Re needs verification.  
- **Actuator Dynamics** – Jets modeled as continuous; real physical actuators may have bandwidth limits.  
- **Error Accumulation** – Slight increase in prediction error during stable wake regimes; may need adaptive horizon or rescaling.  
- **Sensor Placement Robustness** – Algorithm chooses best set for given flow; other geometries may need new SHAP analysis.  
- **Real‑world Implementation** – Requires physical installation of only 4 surface probes; actual sensor noise, drift not simulated.  
- **Training Data Sufficiency** – Data generated from simple modulated signal; for other actuation laws model may need re‑training.  

---------------------------------------------------------------------

## References to Original Sections  

- **Data generation** – Section 2.1  
- **Latent dynamics model** – Section 2.2 (subsections 2.2.1‑2.2.3)  
- **Training losses** – Section 2.2.4  
- **SHAP ranking** – Section 2.3.1  
- **Knowledge distillation** – Section 2.3.2  
- **Cost function** – Section 2.4.1  
- **Experiments results** – Section 3 (subsections 3.1‑3.3).  
- **Conclusions** – Section 4  

---------------------------------------------------------------------

## Executive Summary (Key Take‑aways)  

- *Surface‑only sensing* → feasible in real vehicles.  
- *Offline training* → eliminates online learning risk.  
- *LSTM encoder + residual dynamics+VICReg* → low‑dim, physically shaped manifold.  
- *SHAP + knowledge distillation* → 4‑sensor solution without model performance loss.  
- *Gradient‑based MPC* in PyTorch → real‑time‑feasible with few Adam steps.  
- *Drag reduced 12.8 %* (vs 1.051 baseline) – comparable to experimental AFC on trucks.  
- *Model demonstrates robustness* even when control drives flow into unrepresented states.  

---------------------------------------------------------------------

## Supplementary Material  

- **Data & Code**: Provided as open‑source upon publication.  
- **Appendix**: Not included; all details in main sections.  

---